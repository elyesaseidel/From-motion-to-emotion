{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3383687-559c-4324-8acd-0321d965703a",
   "metadata": {},
   "source": [
    "# 1. Audio to text (with API call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f5106-01e1-4750-b521-e3c979e99bea",
   "metadata": {},
   "source": [
    "Resouce \n",
    "\n",
    "* API \n",
    "https://www.assemblyai.com/app/account\n",
    "\n",
    "* Code \n",
    "https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Conversational-Sentiment-Analysis-6853cafe-37da-4641-aab4-f39fe0f09172/notebook/sentiment%20analysis-48b82162d25a4000ad322296e70cce5a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835276ad-d2ee-48ad-a2d5-0faa840ece56",
   "metadata": {},
   "source": [
    "API condition \n",
    "\n",
    "* Usage limit\t3 hours per month\n",
    "How many hours of audio you can transcribe per month. \n",
    "If you go over this limit, your account access will be suspended until the end of the month.\n",
    "\n",
    "* Concurrency limit\t5\t\n",
    "How many audio files you can have transcribing at any given time. If you submit more than this value at once, \n",
    "files in excess of this limit with sit in a status of \"queued\" until they can be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322fbc8-a549-418f-afc6-d0e5423bcbad",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b309f9-0346-4fb5-83c5-fdf39b07dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests\n",
    "import requests\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af80a6-f68b-4787-a57b-4c29a28fb65c",
   "metadata": {},
   "source": [
    "code for wav file to mp3 covert (incase need in future)\n",
    "\n",
    "You must go for pydub, it is a great module for operations related with audio files.\n",
    "\n",
    "NOTE. Do remember to install ffmpeg before you use pydub.\n",
    "\n",
    "For help regarding installation of ffmpeg, you can use this link.\n",
    "\n",
    "Then to install pydub just open your command prompt and type\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.from_wav(\"/input/file.wav\").export(\"/output/file.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7573ce-8b9f-4f05-aa0f-4b8fff349583",
   "metadata": {},
   "source": [
    "## 1.2 Specify file location and API_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1e8176-5dbc-4c85-8e5f-c9f3430c8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = 'fb9f76369ff849b4a7745a769890cf45'\n",
    "file = '/Users/justinshin/Desktop/Bootcamp/final_project/From-motion-to-emotion/Elyesa/1_speech_to_text_short.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd0c2b-0586-4189-8414-f0a38be0ba72",
   "metadata": {},
   "source": [
    "## 1.3 Specify Upload Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19360893-87d3-4679-a446-237dfb80eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authorization': API_key, \n",
    "    'content-type': 'application/json',\n",
    "}\n",
    "# This holds the API key and the content-type\n",
    "\n",
    "endpoint = 'https://api.assemblyai.com/v2/upload'\n",
    "# This specifies the service to be invoked, \n",
    "# which in this case is the “upload” service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c53858-a4de-4d1d-9ca2-9a93f00a166c",
   "metadata": {},
   "source": [
    "## 1.4 Define the upload function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36251bb3-1d04-4d59-b8fd-14a9f618c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "\n",
    "    with open(file, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(5_242_880)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data\n",
    "            \n",
    "#Audio files can only be uploaded up to a limit of 5 MBs (5,242,880 bytes) at once. \n",
    "#Therefore, we need to upload the data in chunks. These are then merged back on the service endpoint. \n",
    "#Hence, you don’t need to worry about handling numerous URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5ab61-8510-45c0-ac8d-cbb21ef9944c",
   "metadata": {},
   "source": [
    "## 1.5 Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "069454ea-5cac-4a43-a4a8-a111cf5aa37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'upload_url': 'https://cdn.assemblyai.com/upload/0c3fde30-2ed1-470a-b89a-257e32126aeb'}\n"
     ]
    }
   ],
   "source": [
    "res_upload = requests.post(\n",
    "    endpoint, \n",
    "    headers=headers, \n",
    "    data=read_file(file)\n",
    ")\n",
    "\n",
    "print(res_upload.json())\n",
    "\n",
    "upload_url = res_upload.json().get('upload_url')\n",
    "\n",
    "#The last step is to invoke the POST request. \n",
    "#The response of the post request is a JSON that holds the upload_url of the audio file. \n",
    "#I will use this URL for the next steps of executing the sentiment classification on the audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d49ad6-a091-46c1-9764-8e2996df7cf2",
   "metadata": {},
   "source": [
    "## 1.6 Submitting files for Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6993a9-c70f-41fd-906b-0392346dab25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'rjl23b14k1-b726-4bf0-8345-64d8dd9b4552',\n",
       " 'language_model': 'assemblyai_default',\n",
       " 'acoustic_model': 'assemblyai_default',\n",
       " 'language_code': 'en_us',\n",
       " 'status': 'queued',\n",
       " 'audio_url': 'https://cdn.assemblyai.com/upload/0c3fde30-2ed1-470a-b89a-257e32126aeb',\n",
       " 'text': None,\n",
       " 'words': None,\n",
       " 'utterances': None,\n",
       " 'confidence': None,\n",
       " 'audio_duration': None,\n",
       " 'punctuate': True,\n",
       " 'format_text': True,\n",
       " 'dual_channel': None,\n",
       " 'webhook_url': None,\n",
       " 'webhook_status_code': None,\n",
       " 'webhook_auth': False,\n",
       " 'webhook_auth_header_name': None,\n",
       " 'speed_boost': False,\n",
       " 'auto_highlights_result': None,\n",
       " 'auto_highlights': False,\n",
       " 'audio_start_from': None,\n",
       " 'audio_end_at': None,\n",
       " 'word_boost': [],\n",
       " 'boost_param': None,\n",
       " 'filter_profanity': False,\n",
       " 'redact_pii': False,\n",
       " 'redact_pii_audio': False,\n",
       " 'redact_pii_audio_quality': None,\n",
       " 'redact_pii_policies': None,\n",
       " 'redact_pii_sub': None,\n",
       " 'speaker_labels': True,\n",
       " 'content_safety': False,\n",
       " 'iab_categories': False,\n",
       " 'content_safety_labels': {},\n",
       " 'iab_categories_result': {},\n",
       " 'language_detection': False,\n",
       " 'custom_spelling': None,\n",
       " 'cluster_id': None,\n",
       " 'throttled': None,\n",
       " 'auto_chapters': False,\n",
       " 'summarization': False,\n",
       " 'summary_type': None,\n",
       " 'summary_model': None,\n",
       " 'disfluencies': False,\n",
       " 'sentiment_analysis': True,\n",
       " 'sentiment_analysis_results': None,\n",
       " 'chapters': None,\n",
       " 'entity_detection': False,\n",
       " 'entities': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
    "\n",
    "json = {\n",
    "    \"audio_url\": upload_url,\n",
    "    \"sentiment_analysis\": True,\n",
    "    \"speaker_labels\": True\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"authorization\": API_key,\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint, json=json, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23db31-dca2-482b-9e02-c70ff11f6529",
   "metadata": {},
   "source": [
    "## 1.7 Fetching the Transcription result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c503696b-b1d3-444e-88a7-ba9fa3dbdfb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'rjl23b14k1-b726-4bf0-8345-64d8dd9b4552',\n",
       " 'language_model': 'assemblyai_default',\n",
       " 'acoustic_model': 'assemblyai_default',\n",
       " 'language_code': 'en_us',\n",
       " 'status': 'completed',\n",
       " 'audio_url': 'https://cdn.assemblyai.com/upload/0c3fde30-2ed1-470a-b89a-257e32126aeb',\n",
       " 'text': 'The boy wanted to believe that his friend had simply become separated from him by accident.',\n",
       " 'words': [{'text': 'The',\n",
       "   'start': 650,\n",
       "   'end': 766,\n",
       "   'confidence': 0.89,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'boy',\n",
       "   'start': 788,\n",
       "   'end': 1022,\n",
       "   'confidence': 0.91648,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'wanted',\n",
       "   'start': 1076,\n",
       "   'end': 1342,\n",
       "   'confidence': 0.93279,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'to',\n",
       "   'start': 1396,\n",
       "   'end': 1518,\n",
       "   'confidence': 1.0,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'believe',\n",
       "   'start': 1524,\n",
       "   'end': 1790,\n",
       "   'confidence': 0.50961,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'that',\n",
       "   'start': 1860,\n",
       "   'end': 2046,\n",
       "   'confidence': 0.99342,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'his',\n",
       "   'start': 2068,\n",
       "   'end': 2254,\n",
       "   'confidence': 0.99931,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'friend',\n",
       "   'start': 2292,\n",
       "   'end': 2782,\n",
       "   'confidence': 0.75131,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'had',\n",
       "   'start': 2916,\n",
       "   'end': 3214,\n",
       "   'confidence': 0.6229,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'simply',\n",
       "   'start': 3252,\n",
       "   'end': 3594,\n",
       "   'confidence': 0.98827,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'become',\n",
       "   'start': 3642,\n",
       "   'end': 3902,\n",
       "   'confidence': 0.99933,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'separated',\n",
       "   'start': 3956,\n",
       "   'end': 4570,\n",
       "   'confidence': 0.99287,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'from',\n",
       "   'start': 4650,\n",
       "   'end': 4846,\n",
       "   'confidence': 0.99924,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'him',\n",
       "   'start': 4868,\n",
       "   'end': 5006,\n",
       "   'confidence': 0.99843,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'by',\n",
       "   'start': 5028,\n",
       "   'end': 5214,\n",
       "   'confidence': 0.89329,\n",
       "   'speaker': 'A'},\n",
       "  {'text': 'accident.',\n",
       "   'start': 5252,\n",
       "   'end': 5450,\n",
       "   'confidence': 0.98171,\n",
       "   'speaker': 'A'}],\n",
       " 'utterances': [{'confidence': 0.9043100000000002,\n",
       "   'end': 5450,\n",
       "   'speaker': 'A',\n",
       "   'start': 650,\n",
       "   'text': 'The boy wanted to believe that his friend had simply become separated from him by accident.',\n",
       "   'words': [{'text': 'The',\n",
       "     'start': 650,\n",
       "     'end': 766,\n",
       "     'confidence': 0.89,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'boy',\n",
       "     'start': 788,\n",
       "     'end': 1022,\n",
       "     'confidence': 0.91648,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'wanted',\n",
       "     'start': 1076,\n",
       "     'end': 1342,\n",
       "     'confidence': 0.93279,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'to',\n",
       "     'start': 1396,\n",
       "     'end': 1518,\n",
       "     'confidence': 1.0,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'believe',\n",
       "     'start': 1524,\n",
       "     'end': 1790,\n",
       "     'confidence': 0.50961,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'that',\n",
       "     'start': 1860,\n",
       "     'end': 2046,\n",
       "     'confidence': 0.99342,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'his',\n",
       "     'start': 2068,\n",
       "     'end': 2254,\n",
       "     'confidence': 0.99931,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'friend',\n",
       "     'start': 2292,\n",
       "     'end': 2782,\n",
       "     'confidence': 0.75131,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'had',\n",
       "     'start': 2916,\n",
       "     'end': 3214,\n",
       "     'confidence': 0.6229,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'simply',\n",
       "     'start': 3252,\n",
       "     'end': 3594,\n",
       "     'confidence': 0.98827,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'become',\n",
       "     'start': 3642,\n",
       "     'end': 3902,\n",
       "     'confidence': 0.99933,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'separated',\n",
       "     'start': 3956,\n",
       "     'end': 4570,\n",
       "     'confidence': 0.99287,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'from',\n",
       "     'start': 4650,\n",
       "     'end': 4846,\n",
       "     'confidence': 0.99924,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'him',\n",
       "     'start': 4868,\n",
       "     'end': 5006,\n",
       "     'confidence': 0.99843,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'by',\n",
       "     'start': 5028,\n",
       "     'end': 5214,\n",
       "     'confidence': 0.89329,\n",
       "     'speaker': 'A'},\n",
       "    {'text': 'accident.',\n",
       "     'start': 5252,\n",
       "     'end': 5450,\n",
       "     'confidence': 0.98171,\n",
       "     'speaker': 'A'}]}],\n",
       " 'confidence': 0.90431,\n",
       " 'audio_duration': 6,\n",
       " 'punctuate': True,\n",
       " 'format_text': True,\n",
       " 'dual_channel': None,\n",
       " 'webhook_url': None,\n",
       " 'webhook_status_code': None,\n",
       " 'webhook_auth': False,\n",
       " 'webhook_auth_header_name': None,\n",
       " 'speed_boost': False,\n",
       " 'auto_highlights_result': None,\n",
       " 'auto_highlights': False,\n",
       " 'audio_start_from': None,\n",
       " 'audio_end_at': None,\n",
       " 'word_boost': [],\n",
       " 'boost_param': None,\n",
       " 'filter_profanity': False,\n",
       " 'redact_pii': False,\n",
       " 'redact_pii_audio': False,\n",
       " 'redact_pii_audio_quality': None,\n",
       " 'redact_pii_policies': None,\n",
       " 'redact_pii_sub': None,\n",
       " 'speaker_labels': True,\n",
       " 'content_safety': False,\n",
       " 'iab_categories': False,\n",
       " 'content_safety_labels': {'status': 'unavailable',\n",
       "  'results': [],\n",
       "  'summary': {}},\n",
       " 'iab_categories_result': {'status': 'unavailable',\n",
       "  'results': [],\n",
       "  'summary': {}},\n",
       " 'language_detection': False,\n",
       " 'custom_spelling': None,\n",
       " 'cluster_id': None,\n",
       " 'throttled': None,\n",
       " 'auto_chapters': False,\n",
       " 'summarization': False,\n",
       " 'summary_type': None,\n",
       " 'summary_model': None,\n",
       " 'disfluencies': False,\n",
       " 'sentiment_analysis': True,\n",
       " 'chapters': None,\n",
       " 'sentiment_analysis_results': [{'text': 'The boy wanted to believe that his friend had simply become separated from him by accident.',\n",
       "   'start': 650,\n",
       "   'end': 5450,\n",
       "   'sentiment': 'NEUTRAL',\n",
       "   'confidence': 0.6237288117408752,\n",
       "   'speaker': 'A'}],\n",
       " 'entity_detection': False,\n",
       " 'entities': None,\n",
       " 'summary': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_id = response.json()['id']\n",
    "\n",
    "endpoint = f\"https://api.assemblyai.com/v2/transcript/{response_id}\"\n",
    "\n",
    "headers = {\n",
    "    \"authorization\": API_key,\n",
    "}\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b31b29-05e3-4ae3-9f2c-f78cfc132e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The boy wanted to believe that his friend had simply become separated from him by accident.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = response.json()\n",
    "text['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4746f0d5-2dc9-45c8-b09d-201cee317f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "acoustic_model": "assemblyai_default",
       "audio_duration": 6,
       "audio_end_at": null,
       "audio_start_from": null,
       "audio_url": "https://cdn.assemblyai.com/upload/0c3fde30-2ed1-470a-b89a-257e32126aeb",
       "auto_chapters": false,
       "auto_highlights": false,
       "auto_highlights_result": null,
       "boost_param": null,
       "chapters": null,
       "cluster_id": null,
       "confidence": 0.90431,
       "content_safety": false,
       "content_safety_labels": {
        "results": [],
        "status": "unavailable",
        "summary": {}
       },
       "custom_spelling": null,
       "disfluencies": false,
       "dual_channel": null,
       "entities": null,
       "entity_detection": false,
       "filter_profanity": false,
       "format_text": true,
       "iab_categories": false,
       "iab_categories_result": {
        "results": [],
        "status": "unavailable",
        "summary": {}
       },
       "id": "rjl23b14k1-b726-4bf0-8345-64d8dd9b4552",
       "language_code": "en_us",
       "language_detection": false,
       "language_model": "assemblyai_default",
       "punctuate": true,
       "redact_pii": false,
       "redact_pii_audio": false,
       "redact_pii_audio_quality": null,
       "redact_pii_policies": null,
       "redact_pii_sub": null,
       "sentiment_analysis": true,
       "sentiment_analysis_results": [
        {
         "confidence": 0.6237288117408752,
         "end": 5450,
         "sentiment": "NEUTRAL",
         "speaker": "A",
         "start": 650,
         "text": "The boy wanted to believe that his friend had simply become separated from him by accident."
        }
       ],
       "speaker_labels": true,
       "speed_boost": false,
       "status": "completed",
       "summarization": false,
       "summary": null,
       "summary_model": null,
       "summary_type": null,
       "text": "The boy wanted to believe that his friend had simply become separated from him by accident.",
       "throttled": null,
       "utterances": [
        {
         "confidence": 0.9043100000000002,
         "end": 5450,
         "speaker": "A",
         "start": 650,
         "text": "The boy wanted to believe that his friend had simply become separated from him by accident.",
         "words": [
          {
           "confidence": 0.89,
           "end": 766,
           "speaker": "A",
           "start": 650,
           "text": "The"
          },
          {
           "confidence": 0.91648,
           "end": 1022,
           "speaker": "A",
           "start": 788,
           "text": "boy"
          },
          {
           "confidence": 0.93279,
           "end": 1342,
           "speaker": "A",
           "start": 1076,
           "text": "wanted"
          },
          {
           "confidence": 1,
           "end": 1518,
           "speaker": "A",
           "start": 1396,
           "text": "to"
          },
          {
           "confidence": 0.50961,
           "end": 1790,
           "speaker": "A",
           "start": 1524,
           "text": "believe"
          },
          {
           "confidence": 0.99342,
           "end": 2046,
           "speaker": "A",
           "start": 1860,
           "text": "that"
          },
          {
           "confidence": 0.99931,
           "end": 2254,
           "speaker": "A",
           "start": 2068,
           "text": "his"
          },
          {
           "confidence": 0.75131,
           "end": 2782,
           "speaker": "A",
           "start": 2292,
           "text": "friend"
          },
          {
           "confidence": 0.6229,
           "end": 3214,
           "speaker": "A",
           "start": 2916,
           "text": "had"
          },
          {
           "confidence": 0.98827,
           "end": 3594,
           "speaker": "A",
           "start": 3252,
           "text": "simply"
          },
          {
           "confidence": 0.99933,
           "end": 3902,
           "speaker": "A",
           "start": 3642,
           "text": "become"
          },
          {
           "confidence": 0.99287,
           "end": 4570,
           "speaker": "A",
           "start": 3956,
           "text": "separated"
          },
          {
           "confidence": 0.99924,
           "end": 4846,
           "speaker": "A",
           "start": 4650,
           "text": "from"
          },
          {
           "confidence": 0.99843,
           "end": 5006,
           "speaker": "A",
           "start": 4868,
           "text": "him"
          },
          {
           "confidence": 0.89329,
           "end": 5214,
           "speaker": "A",
           "start": 5028,
           "text": "by"
          },
          {
           "confidence": 0.98171,
           "end": 5450,
           "speaker": "A",
           "start": 5252,
           "text": "accident."
          }
         ]
        }
       ],
       "webhook_auth": false,
       "webhook_auth_header_name": null,
       "webhook_status_code": null,
       "webhook_url": null,
       "word_boost": [],
       "words": [
        {
         "confidence": 0.89,
         "end": 766,
         "speaker": "A",
         "start": 650,
         "text": "The"
        },
        {
         "confidence": 0.91648,
         "end": 1022,
         "speaker": "A",
         "start": 788,
         "text": "boy"
        },
        {
         "confidence": 0.93279,
         "end": 1342,
         "speaker": "A",
         "start": 1076,
         "text": "wanted"
        },
        {
         "confidence": 1,
         "end": 1518,
         "speaker": "A",
         "start": 1396,
         "text": "to"
        },
        {
         "confidence": 0.50961,
         "end": 1790,
         "speaker": "A",
         "start": 1524,
         "text": "believe"
        },
        {
         "confidence": 0.99342,
         "end": 2046,
         "speaker": "A",
         "start": 1860,
         "text": "that"
        },
        {
         "confidence": 0.99931,
         "end": 2254,
         "speaker": "A",
         "start": 2068,
         "text": "his"
        },
        {
         "confidence": 0.75131,
         "end": 2782,
         "speaker": "A",
         "start": 2292,
         "text": "friend"
        },
        {
         "confidence": 0.6229,
         "end": 3214,
         "speaker": "A",
         "start": 2916,
         "text": "had"
        },
        {
         "confidence": 0.98827,
         "end": 3594,
         "speaker": "A",
         "start": 3252,
         "text": "simply"
        },
        {
         "confidence": 0.99933,
         "end": 3902,
         "speaker": "A",
         "start": 3642,
         "text": "become"
        },
        {
         "confidence": 0.99287,
         "end": 4570,
         "speaker": "A",
         "start": 3956,
         "text": "separated"
        },
        {
         "confidence": 0.99924,
         "end": 4846,
         "speaker": "A",
         "start": 4650,
         "text": "from"
        },
        {
         "confidence": 0.99843,
         "end": 5006,
         "speaker": "A",
         "start": 4868,
         "text": "him"
        },
        {
         "confidence": 0.89329,
         "end": 5214,
         "speaker": "A",
         "start": 5028,
         "text": "by"
        },
        {
         "confidence": 0.98171,
         "end": 5450,
         "speaker": "A",
         "start": 5252,
         "text": "accident."
        }
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea1e5c-12d8-4764-8785-5cc854adc852",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c83fff-4186-490e-8b0d-23bb6f64b437",
   "metadata": {},
   "source": [
    "## 2.1 Fetching the Transcription result through repeated GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3839f9a-ea44-43e8-a1fd-966f8a1e3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_status = \"queued\"\n",
    "response_id = response.json()['id']\n",
    "endpoint = f\"https://api.assemblyai.com/v2/transcript/{response_id}\"\n",
    "headers = {\n",
    "    \"authorization\": API_key,\n",
    "}\n",
    "\n",
    "while current_status not in (\"completed\", \"error\"):\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    current_status = response.json()['status']\n",
    "    \n",
    "    if current_status in (\"completed\", \"error\"):\n",
    "        print(response)\n",
    "    else:\n",
    "        sleep(10)\n",
    "        \n",
    "current_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b49f7-2db8-412d-8a41-d0546d3565b0",
   "metadata": {},
   "source": [
    "## 2.2 Sentiment Analysis Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9211c33f-6169-4059-a075-ca78e902bd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'The boy wanted to believe that his friend had simply become separated from him by accident.',\n",
       "  'start': 650,\n",
       "  'end': 5450,\n",
       "  'sentiment': 'NEUTRAL',\n",
       "  'confidence': 0.6237288117408752,\n",
       "  'speaker': 'A'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()[\"sentiment_analysis_results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da211c-bb7f-4526-8d7d-2b4c111bd488",
   "metadata": {},
   "source": [
    "## 2.3 Sentiment analysis insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "497e3649-7e38-4c8f-a2bd-ed1b066f4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data = []\n",
    "\n",
    "for idx, sentence in enumerate(response.json()[\"sentiment_analysis_results\"]):\n",
    "\n",
    "    sent = sentence[\"text\"]\n",
    "    sentiment = sentence[\"sentiment\"]\n",
    "    duration = (sentence[\"end\"] - sentence[\"start\"]) / 1000\n",
    "    speaker = sentence[\"speaker\"]\n",
    "    sent_data.append([idx +1 , sent, duration, speaker, sentiment])\n",
    "\n",
    "sent_data = pd.DataFrame(sent_data, \n",
    "                         columns = [\"SentenceID\", \"Text\", \"Duration\", \n",
    "                                    \"Speaker\", \"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2a7b5ba-985f-4721-ae58-7ca144099bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "Name: Speaker, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many speakers \n",
    "sent_data.Speaker#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af957160-d711-4a69-8fc4-8234f5eb6667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257837d1-10ae-4fba-92c4-b029a0e79a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for multiple speakers audio data \n",
    "# 100*sent_data.Speaker.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7cfdc30-c714-4a41-9579-23f32a19cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speaker\n",
       "A    4.8\n",
       "Name: Duration, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duration of speech\n",
    "sent_data.groupby(\"Speaker\").Duration.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cb64e2-3e99-4948-a53e-782c25f7665d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL    1\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment value \n",
    "sent_data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21f9c1df-8561-4861-ba65-e276ed81a60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEUTRAL    100.0\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sent_data.Sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79adcdb4-5e27-4d73-b26c-e20ebcb5f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment  NEUTRAL\n",
      "Speaker           \n",
      "A                1\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(sent_data.Speaker, sent_data.Sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91c9d847-7c27-4838-ab0e-32eff03b617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "NEUTRAL    4.8\n",
       "Name: Duration, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_data.groupby(\"Sentiment\").Duration.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
