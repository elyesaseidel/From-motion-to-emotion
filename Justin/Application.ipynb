{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyesaseidel/motion-to-emotion/blob/main/Justin/Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import "
      ],
      "metadata": {
        "id": "rXP2ns34tN44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QZ1AvmembRUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "013d2c1f-3878-4edc-8213-9e3fa2689afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Installing collected packages: requests, SpeechRecognition\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed SpeechRecognition-3.9.0 requests-2.28.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19792 sha256=85d67c458242362489d23ff077fca0ffd83f7a5e8beb9750a77537574464af92\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/f2/70/526da675d32f17577ec47ac4c663084efe39d47c826b6c3bb1\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-settings\n",
            "  Downloading python_settings-0.2.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: python-settings\n",
            "Successfully installed python-settings-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting synthesizer\n",
            "  Downloading synthesizer-0.2.0.tar.gz (5.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting enum34>=1.1.6\n",
            "  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from synthesizer) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from synthesizer) (1.7.3)\n",
            "Building wheels for collected packages: synthesizer\n",
            "  Building wheel for synthesizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for synthesizer: filename=synthesizer-0.2.0-py2.py3-none-any.whl size=5896 sha256=fb6107632553332b2d85d261eee356d2ebad338a92e219b26b94b2c1a86bf46f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/a3/25/8b8c4afb55e573f4aee46678353677ba520d4d79503f4c8a28\n",
            "Successfully built synthesizer\n",
            "Installing collected packages: enum34, synthesizer\n",
            "Successfully installed enum34-1.1.10 synthesizer-0.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.28.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=45b47b774d9d07b716774c11ac1e65fefb25709f1b9c7cb70e963a56bf650ca5\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/7b/04/4d8d56f1d503e5c404f0de6018c0cfa592c71588a39b49e002\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "imageio"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Collecting moviepy\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.28.2)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Downloading imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.4.8)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
            "Building wheels for collected packages: moviepy\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110742 sha256=06c23d3abf4ddd70be6ea9019ab1d513307f96fb9e8d1c6b83e8a5c1b9fb73c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/a4/db/0368d3a04033da662e13926594b3a8cf1aa4ffeefe570cfac1\n",
            "Successfully built moviepy\n",
            "Installing collected packages: proglog, pillow, imageio, moviepy\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "Successfully installed imageio-2.25.0 moviepy-1.0.3 pillow-9.4.0 proglog-0.1.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "imageio",
                  "moviepy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.78-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from deepface) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.8/dist-packages (from deepface) (4.6.0.66)\n",
            "Collecting fire>=0.4.0\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.8/dist-packages (from deepface) (4.4.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from deepface) (1.1.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.8/dist-packages (from deepface) (1.3.5)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from deepface) (9.4.0)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from deepface) (2.9.2)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.8/dist-packages (from deepface) (4.64.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from deepface) (2.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire>=0.4.0->deepface) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.4.0->deepface) (2.2.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=3.10.1->deepface) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=3.10.1->deepface) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown>=3.10.1->deepface) (2.28.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23.4->deepface) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (4.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (15.0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (23.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (0.30.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (3.19.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.38.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=1be1e2e169dfd05a3159002e1fd261ca776a6d7f34f7a30c29ab497414446410\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, mtcnn, retina-face, deepface\n",
            "Successfully installed deepface-0.0.78 fire-0.5.0 mtcnn-0.1.1 retina-face-0.0.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neattext\n",
            "  Downloading neattext-0.1.3-py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.28.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.12.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit-webrtc\n",
            "  Downloading streamlit_webrtc-0.44.2-py3-none-any.whl (871 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.1/871.1 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from streamlit-webrtc) (23.0)\n",
            "Requirement already satisfied: streamlit>=0.84.1 in /usr/local/lib/python3.8/dist-packages (from streamlit-webrtc) (1.17.0)\n",
            "Collecting cryptography<39\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiortc<2.0.0,>=1.1.2\n",
            "  Downloading aiortc-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.8/dist-packages (from aiortc<2.0.0,>=1.1.2->streamlit-webrtc) (1.5.0)\n",
            "Collecting pyee>=9.0.0\n",
            "  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\n",
            "Collecting aioice<0.8.0,>=0.7.5\n",
            "  Downloading aioice-0.7.6-py3-none-any.whl (23 kB)\n",
            "Collecting pylibsrtp>=0.5.6\n",
            "  Downloading pylibsrtp-0.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av<11.0.0,>=9.0.0\n",
            "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyopenssl>=23.0.0\n",
            "  Downloading pyOpenSSL-23.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from aiortc<2.0.0,>=1.1.2->streamlit-webrtc) (1.15.1)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (9.0.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (13.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (2.28.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (3.19.6)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (5.3.0)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (0.20.0)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (1.3.5)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (2.2.1)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (1.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (6.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (7.1.2)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (1.0.1)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (4.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (3.1.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (2.8.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (1.5.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (4.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (1.21.6)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (6.0.4)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.8/dist-packages (from streamlit>=0.84.1->streamlit-webrtc) (2.13.0)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (33 kB)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from aioice<0.8.0,>=0.7.5->aiortc<2.0.0,>=1.1.2->streamlit-webrtc) (2.3.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (0.12.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (2.11.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.0->aiortc<2.0.0,>=1.1.2->streamlit-webrtc) (2.21)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython!=3.1.19->streamlit>=0.84.1->streamlit-webrtc) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit>=0.84.1->streamlit-webrtc) (3.12.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21.0->streamlit>=0.84.1->streamlit-webrtc) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit>=0.84.1->streamlit-webrtc) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.84.1->streamlit-webrtc) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.84.1->streamlit-webrtc) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.84.1->streamlit-webrtc) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit>=0.84.1->streamlit-webrtc) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.84.1->streamlit-webrtc) (2.1.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.8/dist-packages (from rich>=10.11.0->streamlit>=0.84.1->streamlit-webrtc) (2.14.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit>=0.84.1->streamlit-webrtc) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.84.1->streamlit-webrtc) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (2.0.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.84.1->streamlit-webrtc) (22.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=10.11.0->streamlit>=0.84.1->streamlit-webrtc) (0.1.2)\n",
            "Installing collected packages: netifaces, av, pyee, aioice, pylibsrtp, cryptography, pyopenssl, aiortc, streamlit-webrtc\n",
            "Successfully installed aioice-0.7.6 aiortc-1.4.0 av-10.0.0 cryptography-38.0.4 netifaces-0.11.0 pyee-9.0.4 pylibsrtp-0.8.0 pyopenssl-23.0.0 streamlit-webrtc-0.44.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok\n",
        "!pip install ffmpeg-python\n",
        "!pip install python-settings\n",
        "!pip install synthesizer\n",
        "# !pip install inference\n",
        "# !pip install helper\n",
        "!pip install SpeechRecognition moviepy\n",
        "!pip3 install imageio==2.4.1\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install --upgrade moviepy\n",
        "# !pip install aspect-based-sentiment-analysis==1.1.0\n",
        "!pip install deepface\n",
        "!pip install nltk\n",
        "!pip install neattext\n",
        "!pip install librosa\n",
        "!pip install streamlit-webrtc\n",
        "\n",
        "from moviepy.audio.AudioClip import AudioClip\n",
        "from moviepy.audio.io.readers import FFMPEG_AudioReader\n",
        "import moviepy.editor as mp\n",
        "import neattext.functions as nfx\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from deepface import DeepFace \n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "# import aspect_based_sentiment_analysis as absa\n",
        "from pyngrok import ngrok\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import speech_recognition as sr\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import base64\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# from google.colab.output import eval_js\n",
        "# from IPython.display import HTML, Javascript\n",
        "\n",
        "\n",
        "# https://ngrok.com/ to sign in for free to get auth_key \n",
        "# Tutorial to run streamlit on colab\n",
        "# https://www.youtube.com/watch?v=MUD-pBOnvdo \n",
        "ngrok.set_auth_token('2LC761bNPuCZchtb90lWWFD5sor_G1ecaAUAsAYDSjp6FTD5')\n",
        "\n",
        "# mount your drive with colab notebook\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# # how to read data from google drive\n",
        "# df = pd.read_csv('/content/gdrive/MyDrive/From Motion to Emotion/testing.csv')\n",
        "# # save data to google drive\n",
        "# path = '/content/gdrive/MyDrive/From Motion to Emotion/output.csv'\n",
        "# with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "#   df_alt.to_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit code"
      ],
      "metadata": {
        "id": "pyMGcvERx21o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video resourse \\\n",
        "https://www.youtube.com/watch?v=y9Trdafp83U ('There's more to life than being happy | Emily Esfahani Smith') \\\n",
        "https://www.youtube.com/watch?v=KAJsdgTPJpU&t=1s ('Greta Thunberg's full speech to world leaders at UN Climate Action Summit')\\\n",
        "https://www.youtube.com/watch?v=wD2cVhC-63I ('Matthew McConaughey winning Best Actor | 86th Oscars (2014)')"
      ],
      "metadata": {
        "id": "PFkrApsMiTfe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_XKrKyfcsj5",
        "outputId": "b7360732-034e-4c41-ca3b-2c375b44aa1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Motion_to_Emotion.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Motion_to_Emotion.py \n",
        "import streamlit as st \n",
        "from pyngrok import ngrok\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "import base64\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "from deepface import DeepFace \n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import os\n",
        "import glob\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import moviepy.editor as mp\n",
        "r = sr.Recognizer()\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "import numpy as np\n",
        "import neattext.functions as nfx\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from streamlit_webrtc import VideoTransformerBase, webrtc_streamer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "st.title('Motion to Emotion')\n",
        "\n",
        "image = Image.open('/content/gdrive/MyDrive/From Motion to Emotion/emotion_imgage.jpeg')\n",
        "st.image(image)#, caption='Sunrise by the mountains')\n",
        "\n",
        "st.markdown(\"\"\"---\"\"\")\n",
        "st.header('Upload Video')\n",
        "\n",
        "uploaded_video = st.file_uploader(\"\", type=\"mp4\")\n",
        "\n",
        "if uploaded_video is not None: \n",
        "    vid = uploaded_video.name\n",
        "    with open(vid, mode='wb') as f:\n",
        "        f.write(uploaded_video.read())\n",
        "    path = (uploaded_video.name)\n",
        "    st.video(uploaded_video)\n",
        "\n",
        "st.markdown(\"\"\"---\"\"\")\n",
        "st.header('Choose Video')\n",
        "option = st.selectbox(\n",
        "    '',\n",
        "    ('Choose video',\n",
        "    'Greta Thunberg\\'s speech at UN', \n",
        "    'Emily Esfahani Smith - There\\'s more to life than being happy', \n",
        "    'Matthew McConaughey winning Best Actor 86th Oscars (2014)'))\n",
        "\n",
        "\n",
        "if option == 'Greta Thunberg\\'s speech at UN':\n",
        "  path = '/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4'\n",
        "  st.video(path)\n",
        "\n",
        "if option == 'Emily Esfahani Smith - There\\'s more to life than being happy':\n",
        "  path = '/content/gdrive/MyDrive/From Motion to Emotion/Emily_Happy.mp4'\n",
        "  st.video(path)\n",
        "\n",
        "if option == 'Matthew McConaughey winning Best Actor 86th Oscars (2014)':\n",
        "  path = '/content/gdrive/MyDrive/From Motion to Emotion/Matthew_Oscars.mp4'\n",
        "  st.video(path)\n",
        "\n",
        "st.markdown(\"\"\"---\"\"\")\n",
        "st.header('Analysis Emotion')\n",
        "if st.button('Start'):\n",
        "\n",
        "# Speech Recognition \n",
        "    \n",
        "  clip = mp.VideoFileClip(path) \n",
        "  clip.audio.write_audiofile('audio.wav')\n",
        "\n",
        "  audio = sr.AudioFile(\"audio.wav\")\n",
        "\n",
        "  with audio as source:\n",
        "    audio_file = r.record(source)\n",
        "    text = r.recognize_google(audio_file)\n",
        "\n",
        "\n",
        "# Face emotion dectection \n",
        "# Extrac frames from video \n",
        "  video = cv2.VideoCapture(path)\n",
        "      \n",
        "  total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  step = 30 # if step = 10, then only every 10-th frame will be considered and saved\n",
        "\n",
        "  from collections import Counter\n",
        "  count = 0\n",
        "\n",
        "  frame_list = [] \n",
        "\n",
        "  for i in range(total_frames):\n",
        "      ret, frame = video.read()\n",
        "      if ret:\n",
        "          count += 1\n",
        "          if count % step == 0:\n",
        "              frame_list.append(frame)\n",
        "              \n",
        "  video.release()\n",
        "\n",
        "# Analysis emotion from frames\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  emotions_list = []\n",
        "\n",
        "  for picture in frame_list:\n",
        "    objs = DeepFace.analyze(picture, actions = 'emotion', enforce_detection = False)\n",
        "    dominant_emotion = objs[0]['dominant_emotion']\n",
        "    emotions_list.append(dominant_emotion)\n",
        "\n",
        "# Create datafram from the output\n",
        "\n",
        "  df['Emotion'] = Counter(emotions_list).keys()\n",
        "  df['Counts'] = Counter(emotions_list).values()\n",
        "  df['Percentage'] = (df['Counts']/df['Counts'].sum())*100\n",
        "    \n",
        "  df_sorted = df[['Emotion','Percentage']].sort_values(by = 'Percentage', ascending=False)\n",
        "  df_sorted.reset_index(drop = True, inplace=True)\n",
        "\n",
        "# Dictionary\n",
        "\n",
        "  text_emo = {'angry' : 'Anger',\n",
        "              'fear' : 'Fear',\n",
        "              'fearful' : 'Fear',\n",
        "              'neutral' : 'Neutral', \n",
        "              'sad' : 'Sad', \n",
        "              'disgust' : 'Disgust', \n",
        "              'happy' : 'Happy', \n",
        "              'surprise' : 'Suprise',\n",
        "              'surprised' : 'Suprise',\n",
        "              'neg' : 'Negative',\n",
        "              'neu' : 'Neutral',\n",
        "              'pos' : 'Positive', \n",
        "              'joy' : 'Happy',\n",
        "              'sadness' : 'Sad',\n",
        "              'anger' : 'Anger',\n",
        "              'surprise' : 'Surprise',\n",
        "              }\n",
        "\n",
        "\n",
        "  emoji_emo = {'neutral': ':neutral_face:',\n",
        "            'Neutral':':neutral_face:',\n",
        "            'fear':':scream:',\n",
        "            'fearful':':scream:',\n",
        "            'Fear': ':scream:',\n",
        "            'angry': ':angry:',\n",
        "            'anger' : ':angry:',\n",
        "            'Anger' : ':angry:',\n",
        "            'sad':':cry:',\n",
        "            'Sad' : ':cry:',\n",
        "            'sadness' : ':cry:',\n",
        "            'happy':':grin:',\n",
        "            'Happy':':grin:',\n",
        "            'joy' : ':grin:',\n",
        "            'surprise':':astonished:',\n",
        "            'surprised':':astonished:',\n",
        "            'Surprise':':astonished:',\n",
        "            'disgust':':confounded:',\n",
        "            'Disgust':':confounded:',\n",
        "            'pos' : ':heavy_plus_sign:',\n",
        "            'neg' : ':heavy_minus_sign:',\n",
        "            'neu' : ':black_circle:'\n",
        "            }\n",
        "\n",
        "\n",
        "  \n",
        "# Result displaying \n",
        "  st.markdown(\"\"\"---\"\"\")\n",
        "  with st.container():\n",
        "    st.header(':blue[Speech to Text]')\n",
        "    st.write(text)\n",
        "\n",
        "# Text sentiment analysis \n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    keys_to_keep = ['neg', 'neu', 'pos']\n",
        "    sentiment = {k: sentiment[k] for k in keys_to_keep}\n",
        "    \n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.header(':blue[Text Sentiment]')\n",
        "    \n",
        "    df_sent = pd.DataFrame.from_dict(sentiment,orient='index')\n",
        "    df_sent.reset_index(inplace=True)\n",
        "    df_sent.sort_values(by=0, inplace = True, ascending=False)\n",
        "    df_sent.rename(columns = {'index': 'Sentiment', 0:'Percentage'}, inplace = True)\n",
        "    df_sent.reset_index(drop = True, inplace = True)\n",
        "    df_sent['Percentage'] = df_sent['Percentage']*100\n",
        "    \n",
        "    \n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "      st.title(emoji_emo[df_sent.Sentiment[0]])\n",
        "      st.subheader(text_emo[df_sent.Sentiment[0]])\n",
        "      st.subheader(df_sent.Percentage[0].round(2))\n",
        "      \n",
        "    with col2:\n",
        "      st.title(emoji_emo[df_sent.Sentiment[1]])\n",
        "      st.subheader(text_emo[df_sent.Sentiment[1]])\n",
        "      st.subheader(df_sent.Percentage[1].round(2))\n",
        "     \n",
        "    with col3:\n",
        "      st.title(emoji_emo[df_sent.Sentiment[2]])\n",
        "      st.subheader(text_emo[df_sent.Sentiment[2]])\n",
        "      st.subheader(df_sent.Percentage[2].round(2))\n",
        "\n",
        "\n",
        "# Text Emotion analysis\n",
        "    \n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.header(':blue[Top 3 Text Emotions]')\n",
        "    text_emo_model_path = '/content/gdrive/MyDrive/From Motion to Emotion/emo_text_model_cv.sav'\n",
        "    pipe_lr = pickle.load(open(text_emo_model_path, 'rb'))\n",
        "\n",
        "    text_emo_lst = [(clss, prob) for clss, prob in zip(pipe_lr[\"lr\"].classes_, pipe_lr.predict_proba([text])[0])]\n",
        "    text_emo_df = pd.DataFrame (text_emo_lst)\n",
        "    text_emo_df.rename(columns={0:'emotion', 1: 'percentage'}, inplace = True)\n",
        "    text_emo_df.sort_values(by=\"percentage\", inplace = True, ascending=False)\n",
        "    text_emo_df.reset_index(drop = True, inplace = True)\n",
        "    text_emo_df['percentage'] = text_emo_df['percentage'].apply(lambda x:round(x, 4)*100)\n",
        "  \n",
        "  with st.container():\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "      st.title(emoji_emo[text_emo_df.emotion[0]])\n",
        "      st.subheader(text_emo[text_emo_df.emotion[0]])\n",
        "      st.subheader(text_emo_df.percentage[0].round(2))\n",
        "\n",
        "    with col2:\n",
        "      #if text_emo_df.percentage[1].round(2) > 20:\n",
        "        st.title(emoji_emo[text_emo_df.emotion[1]])\n",
        "        st.subheader(text_emo[text_emo_df.emotion[1]])\n",
        "        st.subheader(text_emo_df.percentage[1].round(2))\n",
        "\n",
        "    with col3:\n",
        "      #if text_emo_df.percentage[2].round(2) > 20:\n",
        "        st.title(emoji_emo[text_emo_df.emotion[2]])\n",
        "        st.subheader(text_emo[text_emo_df.emotion[2]])\n",
        "        st.subheader(text_emo_df.percentage[2].round(2))\n",
        "\n",
        "# Face emotion\n",
        "\n",
        "  with st.container():\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.header(\":blue[Top 3 Face Emotions]\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "      st.title(emoji_emo[df_sorted.Emotion[0]])\n",
        "      st.subheader(text_emo[df_sorted.Emotion[0]])\n",
        "      st.subheader(df_sorted.Percentage[0].round(2))\n",
        "\n",
        "    with col2:\n",
        "      st.title(emoji_emo[df_sorted.Emotion[1]])\n",
        "      st.subheader(text_emo[df_sorted.Emotion[1]])\n",
        "      st.subheader(df_sorted.Percentage[1].round(2))\n",
        "\n",
        "    with col3:\n",
        "      st.title(emoji_emo[df_sorted.Emotion[2]])\n",
        "      st.subheader(text_emo[df_sorted.Emotion[2]])\n",
        "      st.subheader(df_sorted.Percentage[2].round(2))\n",
        "\n",
        "# Spectrogram Prediction\n",
        "      \n",
        "      y, sr = librosa.load('audio.wav')\n",
        "      y, index = librosa.effects.trim(y)  \n",
        "      mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=100)\n",
        "      mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "      spectrogram = librosa.display.specshow(mel_spect, y_axis='mel', fmax=20000, x_axis='time');\n",
        "      plt.axis('off');\n",
        "      plt.savefig('spect.jpeg')\n",
        "\n",
        "      #model = keras.models.load_model('/content/gdrive/MyDrive/From Motion to Emotion/CNN_model.h5')\n",
        "      model = load_model('/content/gdrive/MyDrive/From Motion to Emotion/CNN_model_working.h5', compile=False)\n",
        "      model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "      \n",
        "      image = tf.keras.utils.load_img('spect.jpeg', target_size=(256, 256))\n",
        "      input_arr = tf.keras.utils.img_to_array(image)\n",
        "      input_arr = np.array([input_arr])  \n",
        "      predictions = model.predict(input_arr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      df_spect = pd.DataFrame(predictions, columns = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised'])\n",
        "      df_spect = df_spect.T\n",
        "      df_spect.sort_values(by=0, inplace = True, ascending=False)\n",
        "      df_spect.reset_index(inplace=True)\n",
        "      df_spect.rename(columns = {'index': 'Emotion', 0:'Percentage'}, inplace = True)\n",
        "      df_spect['Percentage'] = df_spect['Percentage']*100\n",
        "            \n",
        "  with st.container():\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.header(\":blue[Top 3 Voice Emotions]\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "      st.title(emoji_emo[df_spect.Emotion[0]])\n",
        "      st.subheader(text_emo[df_spect.Emotion[0]])\n",
        "      st.subheader(df_spect.Percentage[0].round(2))\n",
        "\n",
        "    with col2:\n",
        "      #if df_spect.Percentage[1].round(2) > 20:\n",
        "        st.title(emoji_emo[df_spect.Emotion[1]])\n",
        "        st.subheader(text_emo[df_spect.Emotion[1]])\n",
        "        st.subheader(df_spect.Percentage[1].round(2))\n",
        "\n",
        "    with col3:\n",
        "      #if df_spect.Percentage[2].round(2) > 20:\n",
        "        st.title(emoji_emo[df_spect.Emotion[2]])\n",
        "        st.subheader(text_emo[df_spect.Emotion[2]])\n",
        "        st.subheader(df_spect.Percentage[2].round(2))\n",
        "      \n",
        "\n",
        "# overall emotion ratio  \n",
        "  \n",
        "  overall_list = [] \n",
        "  overall_list.append(text_emo[text_emo_df.emotion[0]])\n",
        "  overall_list.append(text_emo[text_emo_df.emotion[1]])\n",
        "  overall_list.append(text_emo[text_emo_df.emotion[2]])\n",
        "\n",
        "  overall_list.append(text_emo[df_sorted.Emotion[0]])\n",
        "  overall_list.append(text_emo[df_sorted.Emotion[1]])\n",
        "  overall_list.append(text_emo[df_sorted.Emotion[2]])\n",
        "\n",
        "  overall_list.append(text_emo[df_spect.Emotion[0]])\n",
        "  overall_list.append(text_emo[df_spect.Emotion[1]])\n",
        "  overall_list.append(text_emo[df_spect.Emotion[2]])\n",
        "\n",
        "  overall_df = pd.DataFrame (overall_list, columns = ['emotion'])\n",
        "  overall_df = pd.DataFrame(overall_df.value_counts())\n",
        "  overall_df.reset_index(inplace = True)\n",
        "  overall_df['ratio'] = overall_df[0] / 9\n",
        "\n",
        "  with st.container():\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.header(\":red[Overall Top 3 Emotions]\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "      st.title(emoji_emo[overall_df.emotion[0]])\n",
        "      st.subheader(overall_df.emotion[0])\n",
        "      st.subheader((overall_df.ratio[0]*100).round(2))\n",
        "\n",
        "    with col2:\n",
        "      st.title(emoji_emo[overall_df.emotion[1]])\n",
        "      st.subheader(overall_df.emotion[1])\n",
        "      st.subheader((overall_df.ratio[1]*100).round(2))\n",
        "\n",
        "    with col3:\n",
        "      st.title(emoji_emo[overall_df.emotion[2]])\n",
        "      st.subheader(overall_df.emotion[2])\n",
        "      st.subheader((overall_df.ratio[2]*100).round(2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Ngrok tunnel and connect"
      ],
      "metadata": {
        "id": "Mla1OBNFyLlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_nj6JkBRcsuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39f1337-324f-411d-eb48-5b1f371ff4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "NgrokTunnel: \"http://3f6a-35-230-100-41.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "# get tunnel \n",
        "!nohup streamlit run Motion_to_Emotion.py --server.port 80 &\n",
        "url = ngrok.connect(port = '80')\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio recording "
      ],
      "metadata": {
        "id": "CbKIEcH-47Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# js = Javascript(\"\"\"\n",
        "#   async function recordAudio(){\n",
        "#     const div = document.createElement('div');\n",
        "#     const audio = document.createElement('audio');\n",
        "#     const strtButton = document.createElement('button');\n",
        "#     const stopButton = document.createElement('button');\n",
        "\n",
        "#     strtButton.textContent = 'Start Recording';\n",
        "#     stopButton.textContent = 'Stop Recording';\n",
        "\n",
        "#     document.body.appendChild(div);\n",
        "#     div.appendChild(strtButton);\n",
        "#     div.appendChild(audio);\n",
        "\n",
        "#     const stream = await navigator.mediaDevices.getUserMedia({audio:true});\n",
        "#     let recorder = new MediaRecorder(stream);\n",
        "\n",
        "#     audio.style.display = 'block';\n",
        "#     audio.srcObject = stream;\n",
        "#     audio.controls = true;\n",
        "#     audio.muted = true;\n",
        "\n",
        "#     await new Promise((resolve) => strtButton.onclick = resolve);\n",
        "#       strtButton.replaceWith(stopButton);\n",
        "#       recorder.start();\n",
        "\n",
        "#     await new Promise((resolve) => stopButton.onclick = resolve);\n",
        "#       recorder.stop();\n",
        "#       let recData = await new Promise ((resolve) => recorder.ondataavailable = resolve);\n",
        "#       let arrBuff = await recData.data.arrayBuffer();\n",
        "#       stream.getAudioTracks()[0].stop();\n",
        "#       div.remove()\n",
        "      \n",
        "#       let binaryString = '';\n",
        "#       let bytes = new Uint8Array(arrBuff);\n",
        "#       bytes.forEach((byte) => { binaryString += String.fromCharCode(byte)});\n",
        "\n",
        "#     const url = URL.createObjectURL(recData.data);\n",
        "#     const player = document.createElement('audio');\n",
        "#     player.controls = true;\n",
        "#     player.src = url;\n",
        "#     document.body.appendChild(player);\n",
        "  \n",
        "#   return btoa(binaryString)};\n",
        "#   \"\"\")"
      ],
      "metadata": {
        "id": "IQAmNyDBNWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Record audio\n",
        "# display(js)\n",
        "# output = eval_js('recordAudio({})')\n",
        "# with open ('audio.wav','wb') as file:\n",
        "#     binary = base64.b64decode(output)\n",
        "#     file.write(binary)\n",
        "# print('Recording saved to:', file.name)"
      ],
      "metadata": {
        "id": "jbuIRc35RXDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Emotion Detection (DeepFace)"
      ],
      "metadata": {
        "id": "laPMpjoBKGgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "hCGCWrm73c9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary for face emotion \n",
        "Face_emo = {'angry' : 'Anger',\n",
        "              'fear' : 'Fear',\n",
        "              'neutral' : 'Neutral', \n",
        "              'sad' : 'Sad', \n",
        "              'disgust' : 'Disgust', \n",
        "              'happy' : 'Happy', \n",
        "              'surprise' : 'Suprise'\n",
        "              }"
      ],
      "metadata": {
        "id": "qKsoomhJclWz"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrac frames from video \n",
        "video = cv2.VideoCapture('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "    \n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "step = 10 # if step = 10, then only every 10-th frame will be considered and saved\n",
        "\n",
        "from collections import Counter\n",
        "count = 0\n",
        "\n",
        "frame_list = [] \n",
        "\n",
        "for i in range(total_frames):\n",
        "    ret, frame = video.read()\n",
        "    if ret:\n",
        "        count += 1\n",
        "        if count % step == 0:\n",
        "            frame_list.append(frame)\n",
        "            \n",
        "video.release()\n",
        "\n",
        "# Analysis emotion from frames\n",
        "\n",
        "df = pd.DataFrame()\n",
        "emotions_list = []\n",
        "\n",
        "for picture in frame_list:\n",
        "\n",
        "    objs = DeepFace.analyze(picture, actions = 'emotion', enforce_detection = False)\n",
        "    dominant_emotion = objs[0]['dominant_emotion']\n",
        "    emotions_list.append(dominant_emotion)\n",
        "\n",
        "# Create Output\n",
        "df['Emotion'] = Counter(emotions_list).keys()\n",
        "df['Counts'] = Counter(emotions_list).values()\n",
        "df['Percentage'] = (df['Counts']/df['Counts'].sum())*100\n",
        "\n",
        "df_sorted = df[['Emotion','Percentage']].sort_values(by = 'Percentage', ascending=False)\n",
        "df_sorted.reset_index(drop = True, inplace=True)\n"
      ],
      "metadata": {
        "id": "pcuTOEfUKSmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Text from Video"
      ],
      "metadata": {
        "id": "GTgYuJxBctUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clip = mp.VideoFileClip('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4') \n",
        "clip.audio.write_audiofile('Greta_UN.wav')\n",
        "\n",
        "audio = sr.AudioFile(\"Greta_UN.wav\")\n",
        "\n",
        "with audio as source:\n",
        "  audio_file = r.record(source)\n",
        "  text = r.recognize_google(audio_file)\n",
        "\n",
        "text"
      ],
      "metadata": {
        "id": "csL7AT5DfgZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # exporting the result \n",
        "# with open('recognized.txt',mode ='w') as file: \n",
        "#    file.write(\"Recognized Speech:\") \n",
        "#    file.write(\"\\n\") \n",
        "#    file.write(result) \n",
        "#    print(\"ready!\")"
      ],
      "metadata": {
        "id": "TOq8YXGQhUSZ"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aspect-Based Sentiment Analysis(ABSA)"
      ],
      "metadata": {
        "id": "pDQlwH68jcpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install aspect-based-sentiment-analysis\n",
        "# !pip uninstall aspect-based-sentiment-analysis==1.1.0\n",
        "# import aspect_based_sentiment_analysis as absa"
      ],
      "metadata": {
        "id": "cPPqOSQsZLLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nlp = absa.load() \n",
        "# text_1 = (\"this is all wrong I shouldn't be up here I should be back in school on the other side of the ocean yet you all come to us young people for Hope how dare you you have stolen my dreams and my childhood with your empty words and yet I'm one of the lucky ones people are suffering people are dying entire ecosystems are collapsing we are in the beginning of a mass extinction and all you can talk about is the money and fairy tales of Eternal economic growth how dare you\")\n",
        "# people, childhood, ecosystem  = nlp(text_1, aspects = ['people','childhood','ecosystem'])\n",
        "# print(people.sentiment)\n",
        "# print(childhood.sentiment)\n",
        "# print(ecosystem.sentiment)"
      ],
      "metadata": {
        "id": "iY7Uq8A1ipdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"people\", people.sentiment)\n",
        "# print(\"dreams\", dreams.sentiment)\n",
        "# print(\"childhood\", childhood.sentiment)\n",
        "# print(\"ecosystem\", ecosystem.sentiment)\n",
        "# print(\"mass exstinction\", mass_extinction.sentiment)\n",
        "# print(\"fairy tales\", fairy_tales.sentiment)\n",
        "# print(\"ecnonomic growth\", economic_growth.sentiment)"
      ],
      "metadata": {
        "id": "qe2ciqgzlukW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # importance \n",
        "# completed_task = nlp(text_3, aspects=['happiness', 'success', 'job', 'boyfriend', 'apartment', 'feeling', 'friends'])\n",
        "# happiness, success, job, boyfriend, apartment, feeling, friends = completed_task.examples\n",
        "\n",
        "# absa.summary(happiness)\n",
        "# absa.display(happiness.review)\n",
        "\n",
        "# absa.summary(success)\n",
        "# absa.display(success.review)\n",
        "\n",
        "# absa.summary(job)\n",
        "# absa.display(job.review)\n",
        "\n",
        "# absa.summary(boyfriend)\n",
        "# absa.display(boyfriend.review)\n",
        "\n",
        "# absa.summary(apartment)\n",
        "# absa.display(feeling.review)\n",
        "\n",
        "# absa.summary(friends)\n",
        "# absa.display(friends.review)"
      ],
      "metadata": {
        "id": "OSwv8Q0-kNee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Sentiment Analysis"
      ],
      "metadata": {
        "id": "-t0qxDUWs_DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dictionary for text sentiment \n",
        "text_sent = {'neg' : 'Negative',\n",
        "              'neu' : 'Neutral',\n",
        "              'pos' : 'Positive' \n",
        "              }\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "sentiment = sia.polarity_scores(text)\n",
        "# print('Negative', round(sentiment['neg'],2))\n",
        "# print('Neutral', round(sentiment['neu'],2))\n",
        "# print('Positive',round(sentiment['pos'],2))\n",
        "\n",
        "keys_to_keep = ['neg', 'neu', 'pos']\n",
        "sentiment = {k: sentiment[k] for k in keys_to_keep}\n",
        "#print(max(sentiment, key=sentiment.get))\n",
        "# print(text_sent[max(sentiment, key=sentiment.get)])\n",
        "\n",
        "df_sent = pd.DataFrame.from_dict(sentiment,orient='index')\n",
        "df_sent.reset_index(inplace=True)\n",
        "df_sent.sort_values(by=0, inplace = True, ascending=False)\n",
        "df_sent.rename(columns = {'index': 'Sentiment', 0:'Percentage'}, inplace = True)\n",
        "df_sent.reset_index(drop = True, inplace = True)\n",
        "df_sent['Percentage'] = df_sent['Percentage']*100\n",
        "df_sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "W96wpIvEtFal",
        "outputId": "5b1c6e1a-525c-4446-c179-16a930d78a71"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sentiment  Percentage\n",
              "0       neu        76.9\n",
              "1       neg        12.7\n",
              "2       pos        10.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8dcae77-93ac-44c8-8016-8c96aa85fa3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neu</td>\n",
              "      <td>76.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>12.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8dcae77-93ac-44c8-8016-8c96aa85fa3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8dcae77-93ac-44c8-8016-8c96aa85fa3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8dcae77-93ac-44c8-8016-8c96aa85fa3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Emotion Detection "
      ],
      "metadata": {
        "id": "poVK913B-bKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install neattext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import neattext.functions as nfx\n",
        "# Estimators\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Transformers\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/From Motion to Emotion/6_emotion.csv\")\n",
        "df['Emotion'].value_counts()\n",
        "#drop shame emotion \n",
        "df.drop(df[df.Emotion == 'shame'].index, inplace=True)"
      ],
      "metadata": {
        "id": "HYOfHu3K9xw-"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning to training model \n",
        "\n",
        "# df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords) << use this if you want to remove stopwords as well\n",
        "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)\n",
        "\n",
        "\n",
        "Xfeatures = df['Clean_Text']\n",
        "ylabels = df['Emotion']\n",
        "\n",
        "# split data\n",
        "x_train,x_test,y_train,y_test = train_test_split(Xfeatures,ylabels,test_size=0.3,random_state=42)\n",
        "\n",
        "# LogistiticRegression pipeline\n",
        "pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])\n",
        "\n",
        "# train and fit data\n",
        "pipe_lr.fit(x_train,y_train)\n",
        "\n",
        "# with remove_userhandles\n",
        "print(pipe_lr.score(x_test,y_test))\n",
        "\n",
        "# print(pipe_lr.predict([text])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-N9kNDMPZvD",
        "outputId": "af3ce2d4-5a74-47bc-cc4e-8573c2295b69"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6421012122378296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "haZeBrweeizn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model as sav file\n",
        "import pickle\n",
        "\n",
        "pickle.dump(pipe_lr, open('/content/gdrive/MyDrive/From Motion to Emotion/emo_text_model.sav' , 'wb'))"
      ],
      "metadata": {
        "id": "s921-caKT2IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "loaded_model = pickle.load(open('/content/gdrive/MyDrive/From Motion to Emotion/emo_text_model.sav', 'rb'))\n",
        "predict_text_emotion = loaded_model.predict([text])[0]\n",
        "print(predict_text_emotion)"
      ],
      "metadata": {
        "id": "nCUt70UrUHoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show ordered output with emotion name and percentage \n",
        "\n",
        "#show all emotion classes and their probablities together \n",
        "text_emo_lst = [(clss, prob) for clss, prob in zip(pipe_lr[\"lr\"].classes_, pipe_lr.predict_proba([text])[0])]\n",
        "# lst to df\n",
        "text_emo_df = pd.DataFrame (text_emo_lst)\n",
        "# rename columns of df\n",
        "text_emo_df.rename(columns={0:'emotion', 1: 'percentage'}, inplace = True)\n",
        "# sort values\n",
        "text_emo_df.sort_values(by=\"percentage\", inplace = True, ascending=False)\n",
        "# reset index\n",
        "text_emo_df.reset_index(drop = True, inplace = True)\n",
        "# show percentage\n",
        "text_emo_df['percentage'] = text_emo_df['percentage'].apply(lambda x:round(x, 4)*100)\n",
        "text_emo_df"
      ],
      "metadata": {
        "id": "IUL1WHdpI8PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open('/content/gdrive/MyDrive/From Motion to Emotion/emo_text_model_cv.sav', 'rb'))\n",
        "predict_text_emotion = loaded_model.predict([text])[0]\n",
        "print(predict_text_emotion)"
      ],
      "metadata": {
        "id": "1uR-x_66r7Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "p8vutsL1ZOdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Spectrogram from audio"
      ],
      "metadata": {
        "id": "Rmcc5wqYyl3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install librosa\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "# path_save = r'C:\\Users\\Olia\\Desktop\\Lips Reading\\Day5(Video+Audio_camera, CPU)\\CNN_Checkpoints\\test_spec.jpeg'\n",
        "path_load = '/content/gdrive/MyDrive/From Motion to Emotion/03-01-01-01-01-01-01.wav'\n",
        "y, sr = librosa.load(path_load)\n",
        "y, index = librosa.effects.trim(y)\n",
        "mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=100)\n",
        "mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "spectrogram = librosa.display.specshow(mel_spect, y_axis='mel', fmax=20000, x_axis='time');\n",
        "# plt.savefig(path_save)\n",
        "# plt.savefig('test.png')\n",
        "plt.axis('off')\n",
        "plt.savefig('sample.png');"
      ],
      "metadata": {
        "id": "Hl1XOv4nypI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## predict with trained model"
      ],
      "metadata": {
        "id": "ZTnEBu8YfJSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # saving model code \n",
        "# model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n",
        "# model.save('path/to/location')"
      ],
      "metadata": {
        "id": "15mnmmU_dI6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/From Motion to Emotion/CNN_model.h5')\n",
        "# model = keras.models.load_model('/content/gdrive/MyDrive/From Motion to Emotion/CNN_model_working.h5', compile=False)\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model = keras.models.load_model('/content/gdrive/MyDrive/From Motion to Emotion/CNN_model_working.h5', compile=False)"
      ],
      "metadata": {
        "id": "4E77VMT_xPcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "dmKqWGWDhpKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.utils.load_img('/content/sample.png', target_size=(256, 256)) #YOUR IMAGE PSATH\n",
        "input_arr = tf.keras.utils.img_to_array(image)\n",
        "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "predictions = model.predict(input_arr)\n",
        "predictions"
      ],
      "metadata": {
        "id": "3M-tDLYqdMiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PIL\n",
        "from PIL import Image\n",
        "Image.io('/content/sample.png')"
      ],
      "metadata": {
        "id": "SIvuEUCRlIhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spect = pd.DataFrame(predictions, columns = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised'])\n",
        "df_spect = df_spect.T\n",
        "df_spect.sort_values(by=0, inplace = True, ascending=False)\n",
        "df_spect.reset_index(inplace=True)\n",
        "df_spect.rename(columns = {'index': 'Emotion', 0:'Percentage'}, inplace = True)\n",
        "df_spect['Percentage'] = df_spect['Percentage']*100\n",
        "df_spect"
      ],
      "metadata": {
        "id": "oKZZMJWhghpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spect.Percentage[0]"
      ],
      "metadata": {
        "id": "vJFciOYXloQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample one-hot encoding\n",
        "##onehot_encoded = np.array([\"PREDICTION\"]) #[1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1]])\n",
        "\n",
        "# Get the indices where the values are 1\n",
        "##index_of_max = np.argmax(onehot_encoded, axis=1)\n",
        "\n",
        "# Create a list of labels to match the indices\n",
        "labels = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
        "\n",
        "# Use the indices to get the labels\n",
        "decoded_labels = [labels[max_index]]# for index in index_of_max]\n",
        "\n",
        "# The decoded labels\n",
        "print(decoded_labels)"
      ],
      "metadata": {
        "id": "CGPJRq7NeEdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall emotion counting"
      ],
      "metadata": {
        "id": "ARNGJHV11weC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_list= [\"Sad\",\"Happy\",\"Fear\",\"Anger\",\"Happy\",\"Neutral\",\"Happy\",\"Anger\",\"Fear\"]\n",
        "overall_df = pd.DataFrame (overall_list, columns = ['emotion'])\n",
        "overall_df = pd.DataFrame(overall_df.value_counts())\n",
        "overall_df.reset_index(inplace = True)\n",
        "overall_df['ratio'] = overall_df[0] / 9\n",
        "print(overall_df.emotion[0])\n",
        "print((overall_df.ratio[0]*100).round(2))"
      ],
      "metadata": {
        "id": "p1jBoSUf1v1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 19 > 20 :\n",
        "  print ('yes')\n",
        "else:\n",
        "  print('no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pFAEUtk4QiN",
        "outputId": "44e87cf2-ef3b-40e3-e664-32ca1bb6325f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pDQlwH68jcpX"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}