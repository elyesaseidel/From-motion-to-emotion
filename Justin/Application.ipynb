{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyesaseidel/motion-to-emotion/blob/main/Justin/Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QZ1AvmembRUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f70c47-5499-42b5-bd4a-b473ca7a7700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.28.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.8/dist-packages (5.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-settings in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: synthesizer in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.8/dist-packages (from synthesizer) (1.1.10)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from synthesizer) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from synthesizer) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: inference in /usr/local/lib/python3.8/dist-packages (0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: helper in /usr/local/lib/python3.8/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from helper) (6.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install streamlit -q\n",
        "!pip install pyngrok\n",
        "!pip install ffmpeg-python\n",
        "!pip install python-settings\n",
        "!pip install synthesizer\n",
        "!pip install inference\n",
        "!pip install helper\n",
        "!pip install SpeechRecognition moviepy\n",
        "!pip3 install imageio==2.4.1\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install --upgrade moviepy\n",
        "from pyngrok import ngrok\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from IPython.display import HTML, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import base64\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "# https://ngrok.com/ to sign in for free to get auth_key \n",
        "# Tutorial to run streamlit on colab\n",
        "# https://www.youtube.com/watch?v=MUD-pBOnvdo \n",
        "ngrok.set_auth_token('2L2vPxTy5NQV7KFy7pIr8Vrm7M5_4YPqowvfnKA2fyQbtgktr')\n",
        "\n",
        "# mount your drive with colab notebook\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing - download and save file from/to google drive "
      ],
      "metadata": {
        "id": "Z8n7pnSnxnEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/From Motion to Emotion/testing.csv')"
      ],
      "metadata": {
        "id": "cVfAMOFZwI8S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ReRp8auywI47",
        "outputId": "5a7d50f5-af34-40fc-88f6-07f038fdf03f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  icao iata        city_full_name  \\\n",
              "0           0  EDDT  TXL  Berlin, Berlin-Tegel   \n",
              "1           1  EDDT  TXL  Berlin, Berlin-Tegel   \n",
              "\n",
              "                             location country_code  \n",
              "0  {'lat': 52.5597, 'lon': 13.287699}           DE  \n",
              "1  {'lat': 52.5597, 'lon': 13.287699}           DE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99007dae-02bb-4703-9c03-4b85a40e4b14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>icao</th>\n",
              "      <th>iata</th>\n",
              "      <th>city_full_name</th>\n",
              "      <th>location</th>\n",
              "      <th>country_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>EDDT</td>\n",
              "      <td>TXL</td>\n",
              "      <td>Berlin, Berlin-Tegel</td>\n",
              "      <td>{'lat': 52.5597, 'lon': 13.287699}</td>\n",
              "      <td>DE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>EDDT</td>\n",
              "      <td>TXL</td>\n",
              "      <td>Berlin, Berlin-Tegel</td>\n",
              "      <td>{'lat': 52.5597, 'lon': 13.287699}</td>\n",
              "      <td>DE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99007dae-02bb-4703-9c03-4b85a40e4b14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99007dae-02bb-4703-9c03-4b85a40e4b14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99007dae-02bb-4703-9c03-4b85a40e4b14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_alt = df[:3]"
      ],
      "metadata": {
        "id": "1EQ7uVmbtnEN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/From Motion to Emotion/output.csv'\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  df_alt.to_csv(f)"
      ],
      "metadata": {
        "id": "7cKGtf5ywvDn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit code"
      ],
      "metadata": {
        "id": "pyMGcvERx21o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_XKrKyfcsj5",
        "outputId": "d0f5c149-3fef-40c1-f088-d86460b99d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Motion_to_Emotion.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Motion_to_Emotion.py \n",
        "import streamlit as st \n",
        "from pyngrok import ngrok\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from IPython.display import Javascript\n",
        "import base64\n",
        "from base64 import b64decode\n",
        "from google.colab.output import eval_js\n",
        "import cv2\n",
        "from deepface import DeepFace \n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import moviepy.editor as mp\n",
        "r = sr.Recognizer()\n",
        "\n",
        "image = Image.open('/content/gdrive/MyDrive/From Motion to Emotion/emotion_imgage.jpeg')\n",
        "st.image(image)#, caption='Sunrise by the mountains')\n",
        "\n",
        "st.title('Motion to Emotion')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "option = st.selectbox(\n",
        "    'Select a video to analyse',\n",
        "    ('Greta Thunberg\\'s speech at UN', 'option2', 'option3'))\n",
        "\n",
        "st.write('You selected:', option)\n",
        "\n",
        "if option == 'Greta Thunberg\\'s speech at UN':\n",
        "  st.subheader('Greta Thunberg\\'s speech at UN')\n",
        "  st.video('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "  if st.button('Start Analysis'):\n",
        "\n",
        "\n",
        "# Speech Recognition \n",
        "    clip = mp.VideoFileClip('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4') \n",
        "    clip.audio.write_audiofile('Greta_UN.wav')\n",
        "\n",
        "    audio = sr.AudioFile(\"Greta_UN.wav\")\n",
        "\n",
        "    with audio as source:\n",
        "      audio_file = r.record(source)\n",
        "      result = r.recognize_google(audio_file)\n",
        "\n",
        "\n",
        "\n",
        "# Face emotion dectection \n",
        "    # Extrac frames from video \n",
        "    video = cv2.VideoCapture('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "        \n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    step = 30 # if step = 10, then only every 10-th frame will be considered and saved\n",
        "\n",
        "    from collections import Counter\n",
        "    count = 0\n",
        "\n",
        "    frame_list = [] \n",
        "\n",
        "    for i in range(total_frames):\n",
        "        ret, frame = video.read()\n",
        "        if ret:\n",
        "            count += 1\n",
        "            if count % step == 0:\n",
        "                frame_list.append(frame)\n",
        "                \n",
        "    video.release()\n",
        "\n",
        "    # Analysis emotion from frames\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    emotions_list = []\n",
        "\n",
        "    for picture in frame_list:\n",
        "\n",
        "        objs = DeepFace.analyze(picture, actions = 'emotion', enforce_detection = False)\n",
        "        dominant_emotion = objs[0]['dominant_emotion']\n",
        "        emotions_list.append(dominant_emotion)\n",
        "\n",
        "    # Create Output\n",
        "    df['Emotion'] = Counter(emotions_list).keys()\n",
        "    df['Counts'] = Counter(emotions_list).values()\n",
        "    df['Percentage'] = (df['Counts']/df['Counts'].sum())*100\n",
        "    \n",
        "#    st.markdown('Face Emotion Detection during the video')\n",
        "#    st.dataframe(df)\n",
        "    \n",
        "#    st.markdown('Most Domiant Emotion during the video')\n",
        "#    st.dataframe(df[df.Percentage == df.Percentage.max()])\n",
        "\n",
        "    percent = df.Percentage.max().round(2)\n",
        "\n",
        "    df_sorted = df[['Emotion','Percentage']].sort_values(by = 'Percentage', ascending=False)\n",
        "    df_sorted.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Result Columns \n",
        "\n",
        "    with st.container():\n",
        "      st.header('Speech Recognition')\n",
        "      st.write(result)\n",
        "\n",
        "    with st.container():\n",
        "      st.header(\"Face Emotion\")\n",
        "      col1, col2, col3 = st.columns(3)\n",
        "      \n",
        "      with col1:\n",
        "        st.write('Most Deminant Face Emotion')\n",
        "        if df_sorted.Emotion[0] == 'fear':\n",
        "          st.title(':anguished:')\n",
        "          st.subheader('Fear')\n",
        "          st.header(percent)\n",
        "\n",
        "      with col2:\n",
        "        st.write('Second Deminant Face Emotion')\n",
        "        if df_sorted.Emotion[0] == 'fear':\n",
        "          st.title(':anguished:')\n",
        "          st.subheader('Fear')\n",
        "          st.header(percent)      \n",
        "\n",
        "      with col3:\n",
        "        st.write('Second Deminant Face Emotion')\n",
        "        if df_sorted.Emotion[0] == 'fear':\n",
        "          st.title(':anguished:')\n",
        "          st.subheader('Fear')\n",
        "          st.header(percent)     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "DDZmzOVBcigy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Ngrok tunnel and connect"
      ],
      "metadata": {
        "id": "Mla1OBNFyLlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_nj6JkBRcsuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae7518c-04ab-4149-92d1-eb14f0433051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "NgrokTunnel: \"http://1122-34-80-44-56.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "# get tunnel \n",
        "!nohup streamlit run Motion_to_Emotion.py --server.port 80 &\n",
        "url = ngrok.connect(port = '80')\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio recording "
      ],
      "metadata": {
        "id": "CbKIEcH-47Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "js = Javascript(\"\"\"\n",
        "  async function recordAudio(){\n",
        "    const div = document.createElement('div');\n",
        "    const audio = document.createElement('audio');\n",
        "    const strtButton = document.createElement('button');\n",
        "    const stopButton = document.createElement('button');\n",
        "\n",
        "    strtButton.textContent = 'Start Recording';\n",
        "    stopButton.textContent = 'Stop Recording';\n",
        "\n",
        "    document.body.appendChild(div);\n",
        "    div.appendChild(strtButton);\n",
        "    div.appendChild(audio);\n",
        "\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({audio:true});\n",
        "    let recorder = new MediaRecorder(stream);\n",
        "\n",
        "    audio.style.display = 'block';\n",
        "    audio.srcObject = stream;\n",
        "    audio.controls = true;\n",
        "    audio.muted = true;\n",
        "\n",
        "    await new Promise((resolve) => strtButton.onclick = resolve);\n",
        "      strtButton.replaceWith(stopButton);\n",
        "      recorder.start();\n",
        "\n",
        "    await new Promise((resolve) => stopButton.onclick = resolve);\n",
        "      recorder.stop();\n",
        "      let recData = await new Promise ((resolve) => recorder.ondataavailable = resolve);\n",
        "      let arrBuff = await recData.data.arrayBuffer();\n",
        "      stream.getAudioTracks()[0].stop();\n",
        "      div.remove()\n",
        "      \n",
        "      let binaryString = '';\n",
        "      let bytes = new Uint8Array(arrBuff);\n",
        "      bytes.forEach((byte) => { binaryString += String.fromCharCode(byte)});\n",
        "\n",
        "    const url = URL.createObjectURL(recData.data);\n",
        "    const player = document.createElement('audio');\n",
        "    player.controls = true;\n",
        "    player.src = url;\n",
        "    document.body.appendChild(player);\n",
        "  \n",
        "  return btoa(binaryString)};\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "IQAmNyDBNWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record audio\n",
        "display(js)\n",
        "output = eval_js('recordAudio({})')\n",
        "with open ('audio.wav','wb') as file:\n",
        "    binary = base64.b64decode(output)\n",
        "    file.write(binary)\n",
        "print('Recording saved to:', file.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "jbuIRc35RXDv",
        "outputId": "8f99f7b4-6518-4b41-e83c-523792e64eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  async function recordAudio(){\n",
              "    const div = document.createElement('div');\n",
              "    const audio = document.createElement('audio');\n",
              "    const strtButton = document.createElement('button');\n",
              "    const stopButton = document.createElement('button');\n",
              "\n",
              "    strtButton.textContent = 'Start Recording';\n",
              "    stopButton.textContent = 'Stop Recording';\n",
              "\n",
              "    document.body.appendChild(div);\n",
              "    div.appendChild(strtButton);\n",
              "    div.appendChild(audio);\n",
              "\n",
              "    const stream = await navigator.mediaDevices.getUserMedia({audio:true});\n",
              "    let recorder = new MediaRecorder(stream);\n",
              "\n",
              "    audio.style.display = 'block';\n",
              "    audio.srcObject = stream;\n",
              "    audio.controls = true;\n",
              "    audio.muted = true;\n",
              "\n",
              "    await new Promise((resolve) => strtButton.onclick = resolve);\n",
              "      strtButton.replaceWith(stopButton);\n",
              "      recorder.start();\n",
              "\n",
              "    await new Promise((resolve) => stopButton.onclick = resolve);\n",
              "      recorder.stop();\n",
              "      let recData = await new Promise ((resolve) => recorder.ondataavailable = resolve);\n",
              "      let arrBuff = await recData.data.arrayBuffer();\n",
              "      stream.getAudioTracks()[0].stop();\n",
              "      div.remove()\n",
              "      \n",
              "      let binaryString = '';\n",
              "      let bytes = new Uint8Array(arrBuff);\n",
              "      bytes.forEach((byte) => { binaryString += String.fromCharCode(byte)});\n",
              "\n",
              "    const url = URL.createObjectURL(recData.data);\n",
              "    const player = document.createElement('audio');\n",
              "    player.controls = true;\n",
              "    player.src = url;\n",
              "    document.body.appendChild(player);\n",
              "  \n",
              "  return btoa(binaryString)};\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording saved to: audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepFace Emotion Detection"
      ],
      "metadata": {
        "id": "1Uc_jA6X5QaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface\n",
        "import cv2"
      ],
      "metadata": {
        "id": "rXP4bm6t5U_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the video file from a folder \n",
        "video = cv2.VideoCapture('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "    \n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Set the step\n",
        "step = 10 # if step = 10, then only every 10-th frame will be considered and saved\n",
        "\n",
        "# Initialize the counter\n",
        "from collections import Counter\n",
        "count = 0\n",
        "\n",
        "frame_list = [] \n",
        "# Iterate over each frame\n",
        "for i in range(total_frames):\n",
        "    ret, frame = video.read()\n",
        "    if ret:\n",
        "        count += 1\n",
        "        if count % step == 0:\n",
        "            frame_list.append(frame)\n",
        "            #cv2.imwrite('/content/gdrive/MyDrive/From Motion to Emotion/picture/frame{}.jpg'.format(i), frame)\n",
        "video.release()"
      ],
      "metadata": {
        "id": "JgaUDVuG5VWG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_list"
      ],
      "metadata": {
        "id": "TZeursSQJJbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import JSON #uncomment in case of an error\n",
        "from deepface import DeepFace # to work with faces\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.DataFrame()\n",
        "list_frames_emotions = []\n",
        "\n",
        "# video_frames_path = Path('/content/gdrive/MyDrive/From Motion to Emotion/picture')\n",
        "\n",
        "# os.chdir(video_frames_path)\n",
        "\n",
        "# video_frames = glob.glob(\"./*\")\n",
        "\n",
        "for picture in frame_list:\n",
        "\n",
        "    objs = DeepFace.analyze(picture, actions = 'emotion', enforce_detection = False)\n",
        "    dominant_emotion = objs[0]['dominant_emotion']\n",
        "    list_frames_emotions.append(dominant_emotion)\n",
        "\n",
        "df['Emotion'] = Counter(list_frames_emotions).keys()\n",
        "df['Counts'] = Counter(list_frames_emotions).values()\n",
        "df['Percentage'] = (df['Counts']/df['Counts'].sum())*100\n",
        "print(df)\n",
        "print(df[df.Percentage == df.Percentage.max()])\n"
      ],
      "metadata": {
        "id": "IqsefHH05VTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most domiant emotion of the face expression\n",
        "print(df[df.Percentage == df.Percentage.max()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYQZNpTMBfgv",
        "outputId": "e4bb9ea1-c735-422f-aa32-92eab7a16cfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Emotion  Counts  Percentage\n",
            "1    fear      59   40.689655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video-Frame-DeepFace-Output (One Code)"
      ],
      "metadata": {
        "id": "laPMpjoBKGgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install deepface\n",
        "import cv2\n",
        "from deepface import DeepFace \n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "from collections import Counter\n",
        "\n",
        "# Extrac frames from video \n",
        "video = cv2.VideoCapture('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "    \n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "step = 10 # if step = 10, then only every 10-th frame will be considered and saved\n",
        "\n",
        "from collections import Counter\n",
        "count = 0\n",
        "\n",
        "frame_list = [] \n",
        "\n",
        "for i in range(total_frames):\n",
        "    ret, frame = video.read()\n",
        "    if ret:\n",
        "        count += 1\n",
        "        if count % step == 0:\n",
        "            frame_list.append(frame)\n",
        "            \n",
        "video.release()\n",
        "\n",
        "# Analysis emotion from frames\n",
        "\n",
        "df = pd.DataFrame()\n",
        "emotions_list = []\n",
        "\n",
        "for picture in frame_list:\n",
        "\n",
        "    objs = DeepFace.analyze(picture, actions = 'emotion', enforce_detection = False)\n",
        "    dominant_emotion = objs[0]['dominant_emotion']\n",
        "    emotions_list.append(dominant_emotion)\n",
        "\n",
        "# Create Output\n",
        "df['Emotion'] = Counter(emotions_list).keys()\n",
        "df['Counts'] = Counter(emotions_list).values()\n",
        "df['Percentage'] = (df['Counts']/df['Counts'].sum())*100\n",
        "print(df)\n",
        "print(df[df.Percentage == df.Percentage.max()])\n"
      ],
      "metadata": {
        "id": "pcuTOEfUKSmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "0VQ73lfIBzok",
        "outputId": "3f1aa1fe-d2b2-4b2c-cbd7-84ed79b5a7ec"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Emotion  Counts  Percentage\n",
              "0   neutral      15   10.344828\n",
              "1      fear      59   40.689655\n",
              "2     angry      28   19.310345\n",
              "3       sad      22   15.172414\n",
              "4     happy      12    8.275862\n",
              "5  surprise       7    4.827586\n",
              "6   disgust       2    1.379310"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5690c95-6df0-4235-b239-e3608b99c26c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Counts</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>15</td>\n",
              "      <td>10.344828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>59</td>\n",
              "      <td>40.689655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>angry</td>\n",
              "      <td>28</td>\n",
              "      <td>19.310345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sad</td>\n",
              "      <td>22</td>\n",
              "      <td>15.172414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happy</td>\n",
              "      <td>12</td>\n",
              "      <td>8.275862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>surprise</td>\n",
              "      <td>7</td>\n",
              "      <td>4.827586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>disgust</td>\n",
              "      <td>2</td>\n",
              "      <td>1.379310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5690c95-6df0-4235-b239-e3608b99c26c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5690c95-6df0-4235-b239-e3608b99c26c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5690c95-6df0-4235-b239-e3608b99c26c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percent = df.Percentage.max().round(2)"
      ],
      "metadata": {
        "id": "PGf_VLR05_w9"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (percent, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugi6Gb2GHdoC",
        "outputId": "0716ee5c-fb60-4c49-8613-4a743244b65d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40.69 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-MGRsdiQHcEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = df[['Emotion','Percentage']].sort_values(by = 'Percentage', ascending=False)"
      ],
      "metadata": {
        "id": "Hpf0JsI17zBT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "iUSOuTKR8N9q"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_sorted[['Emotion','Percentage']] \n",
        "df_sorted.iloc[[1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yjyhdgw_8hRe",
        "outputId": "ed0f2da0-aeb1-4a5f-bfaf-12a437c4c0e1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index Emotion  Percentage\n",
              "1      2   angry   19.310345"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d798700-7701-4841-b828-6ab7ca653764\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>angry</td>\n",
              "      <td>19.310345</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d798700-7701-4841-b828-6ab7ca653764')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d798700-7701-4841-b828-6ab7ca653764 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d798700-7701-4841-b828-6ab7ca653764');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df_sorted.Emotion[1] == 'fear':\n",
        "  print('yes')\n",
        "  \n",
        "else:\n",
        "    print('no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0rEyUj_8wWH",
        "outputId": "157ddb5a-0427-417f-bc08-de69d8df4a78"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "      # with col1:\n",
        "      #   st.write('Most Deminant Face Emotion')\n",
        "      #   if df_sorted.Emotion[0] == 'fear':\n",
        "      #     st.title(':anguished:')\n",
        "      #     st.subheader('Fear')\n",
        "      #     st.header(percent)\n"
      ],
      "metadata": {
        "id": "cVG6RNw5MyMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted.Emotion[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9Za-uVdm8wPU",
        "outputId": "d91c9e0b-ad10-4532-938b-fd99b58074ad"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'angry'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted[['Emotion','Percentage']][:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Xt_MaoErNecY",
        "outputId": "99d8eef0-14f8-4551-966a-2b45fa5c3e6f"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Emotion  Percentage\n",
              "0    fear   40.689655"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f89d21-abdb-41cb-b358-ab5cb3bb33ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fear</td>\n",
              "      <td>40.689655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f89d21-abdb-41cb-b358-ab5cb3bb33ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48f89d21-abdb-41cb-b358-ab5cb3bb33ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48f89d21-abdb-41cb-b358-ab5cb3bb33ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if i in len(df_sorted.Emotion):\n",
        "  df_sorted.Emotion[i] == 'fear'\n",
        "  print('fear')\n",
        "elif df_sorted.Emotion[i] == 'angry':\n",
        "  print('angry')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "b53bj2k4MLZD",
        "outputId": "7bf246ec-8820-43a7-cec0-c34da26b5adb"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-1b48c0540e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fear'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'angry'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Text from Video"
      ],
      "metadata": {
        "id": "GTgYuJxBctUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install imageio-ffmpeg\n",
        "import speech_recognition as sr\n",
        "from moviepy.audio.AudioClip import AudioClip\n",
        "from moviepy.audio.io.readers import FFMPEG_AudioReader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "GNCLun60dEbf",
        "outputId": "1668dc95-de0f-4dac-b65c-051cbeb84323"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0de7ac4c50eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# !pip install imageio-ffmpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFFMPEG_AudioReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/moviepy/audio/AudioClip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg_audiowriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mffmpeg_audiowrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires_duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated_version_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/moviepy/audio/io/ffmpeg_audiowriter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires_duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/moviepy/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ffmpeg-imageio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mFFMPEG_BINARY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto-detect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\" Wrapper for imageio_ffmpeg.get_ffmpeg_exe()\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimageio_ffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ffmpeg_exe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio_ffmpeg'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioclip = AudioFileClip('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4')\n",
        "# audioclip.write_audiofile(f\"audio_from_video_sm.wav\")\n",
        "# audio_to_be_text = (f\"audio_from_video_sm.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "lQpX4EV8cy9v",
        "outputId": "60d077ae-19f1-4271-ed7f-2597e8f42d98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-8a00e03093db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudioclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# audioclip.write_audiofile(f\"audio_from_video_sm.wav\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# audio_to_be_text = (f\"audio_from_video_sm.wav\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AudioFileClip' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = sr.Recognizer()\n",
        "\n",
        "# open the file\n",
        "with sr.AudioFile(audio_to_be_text) as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "DnAttSz7c2y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## new approach"
      ],
      "metadata": {
        "id": "3pns2aonjhwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition moviepy\n",
        "!pip3 install imageio==2.4.1\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install --upgrade moviepy\n",
        "import speech_recognition as sr \n",
        "import moviepy.editor as mp\n",
        "r = sr.Recognizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqJaQUkffP6i",
        "outputId": "d8f69153-8790-4418-e8b6-4f8001ad1d01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.28.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.25.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Using cached imageio-2.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (1.21.6)\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.0\n",
            "    Uninstalling imageio-2.25.0:\n",
            "      Successfully uninstalled imageio-2.25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.8/dist-packages (0.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (1.0.3)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.4.8)\n",
            "Collecting imageio<3.0,>=2.5\n",
            "  Using cached imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.28.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.8/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed imageio-2.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = mp.VideoFileClip('/content/gdrive/MyDrive/From Motion to Emotion/Greta_UN.mp4') \n",
        "clip.audio.write_audiofile('Greta_UN.wav')\n",
        "\n",
        "audio = sr.AudioFile(\"Greta_UN.wav\")\n",
        "\n",
        "with audio as source:\n",
        "  audio_file = r.record(source)\n",
        "  result = r.recognize_google(audio_file)\n",
        "\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "csL7AT5DfgZc",
        "outputId": "0105b1ed-651c-438a-dae4-de20215d134d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in Greta_UN.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "result2:\n",
            "{   'alternative': [   {   'confidence': 0.95733714,\n",
            "                           'transcript': \"this is all wrong I shouldn't be up \"\n",
            "                                         'here I should be back in school on '\n",
            "                                         'the other side of the ocean yet you '\n",
            "                                         'all come to us young people for Hope '\n",
            "                                         'how dare you you have stolen my '\n",
            "                                         'dreams and my childhood with your '\n",
            "                                         \"empty words and yet I'm one of the \"\n",
            "                                         'lucky ones people are suffering '\n",
            "                                         'people are dying entire ecosystems '\n",
            "                                         'are collapsing we are in the '\n",
            "                                         'beginning of a mass extinction and '\n",
            "                                         'all you can talk about is the money '\n",
            "                                         'and fairy tales of Eternal economic '\n",
            "                                         'growth how dare you'},\n",
            "                       {   'transcript': \"this is all wrong I shouldn't be up \"\n",
            "                                         'here I should be back in school on '\n",
            "                                         'the other side of the ocean yet you '\n",
            "                                         'all come to us young people for Hope '\n",
            "                                         'how dare you you have stolen my '\n",
            "                                         'dreams and my childhood with your '\n",
            "                                         \"empty words and yet I'm one of the \"\n",
            "                                         'lucky ones people are suffering '\n",
            "                                         'people are dying entire ecosystems '\n",
            "                                         'are collapsing we are in the '\n",
            "                                         'beginning of a mass extinction and '\n",
            "                                         'all you can talk about is money and '\n",
            "                                         'fairy tales of Eternal economic '\n",
            "                                         'growth how dare you'},\n",
            "                       {   'transcript': \"this is all wrong I shouldn't be up \"\n",
            "                                         'here I should be back in school on '\n",
            "                                         'the other side of the ocean yet you '\n",
            "                                         'all come to us young people for Hope '\n",
            "                                         'how dare you you have stolen my '\n",
            "                                         'dreams and my childhood with your '\n",
            "                                         \"empty words yet I'm one of the lucky \"\n",
            "                                         'ones people are suffering people are '\n",
            "                                         'dying entire ecosystems are '\n",
            "                                         'collapsing we are in the beginning '\n",
            "                                         'of a mass extinction and all you can '\n",
            "                                         'talk about is the money and fairy '\n",
            "                                         'tales of Eternal economic growth how '\n",
            "                                         'dare you'},\n",
            "                       {   'transcript': \"this is all wrong I shouldn't be up \"\n",
            "                                         'here I should be back in school on '\n",
            "                                         'the other side of the ocean yet you '\n",
            "                                         'all come to us young people for Hope '\n",
            "                                         'how dare you you have stolen my '\n",
            "                                         'dreams and my childhood with your '\n",
            "                                         \"empty words yet I'm one of the lucky \"\n",
            "                                         'ones people are suffering people are '\n",
            "                                         'dying entire ecosystems are '\n",
            "                                         'collapsing we are in the beginning '\n",
            "                                         'of a mass extinction and all you can '\n",
            "                                         'talk about is money and fairy tales '\n",
            "                                         'of Eternal economic growth how dare '\n",
            "                                         'you'},\n",
            "                       {   'transcript': \"this is so wrong I shouldn't be up \"\n",
            "                                         'here I should be back in school on '\n",
            "                                         'the other side of the ocean yet you '\n",
            "                                         'all come to us young people for Hope '\n",
            "                                         'how dare you you have stolen my '\n",
            "                                         'dreams and my childhood with your '\n",
            "                                         \"empty words and yet I'm one of the \"\n",
            "                                         'lucky ones people are suffering '\n",
            "                                         'people are dying entire ecosystems '\n",
            "                                         'are collapsing we are in the '\n",
            "                                         'beginning of a mass extinction and '\n",
            "                                         'all you can talk about is the money '\n",
            "                                         'and fairy tales of Eternal economic '\n",
            "                                         'growth how dare you'}],\n",
            "    'final': True}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"this is all wrong I shouldn't be up here I should be back in school on the other side of the ocean yet you all come to us young people for Hope how dare you you have stolen my dreams and my childhood with your empty words and yet I'm one of the lucky ones people are suffering people are dying entire ecosystems are collapsing we are in the beginning of a mass extinction and all you can talk about is the money and fairy tales of Eternal economic growth how dare you\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio = sr.AudioFile(\"conveGreta_UNrted.wav\")"
      ],
      "metadata": {
        "id": "wkEnE2OUhUfz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with audio as source:\n",
        "  audio_file = r.record(source)\n",
        "  result = r.recognize_google(audio_file)"
      ],
      "metadata": {
        "id": "Rmw7UCTZhUcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "QK9ioSmRlWN-",
        "outputId": "c694021f-8b6a-4acc-af31-7ba3709a7775"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"this is all wrong I shouldn't be up here I should be back in school on the other side of the ocean yet you all come to us young people for Hope how dare you you have stolen my dreams and my childhood with your empty words and yet I'm one of the lucky ones people are suffering people are dying entire ecosystems are collapsing we are in the beginning of a mass extinction and all you can talk about is the money and fairy tales of Eternal economic growth how dare you\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZR83PaulWJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting the result \n",
        "with open('recognized.txt',mode ='w') as file: \n",
        "   file.write(\"Recognized Speech:\") \n",
        "   file.write(\"\\n\") \n",
        "   file.write(result) \n",
        "   print(\"ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq8YXGQhUSZ",
        "outputId": "13354a0c-f28c-4dab-aaa0-f8f5dc328727"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 new approach"
      ],
      "metadata": {
        "id": "_iu7Yfqlj25i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SFv5SXSnEgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tkinter import *\n",
        "import moviepy.editor as mp \n",
        "import speech_recognition as sr\n",
        "\n",
        "\n",
        "root=Tk()\n",
        "root.geometry('750x420+480+0')\n",
        "root.resizable(False,False)\n",
        "root.config(bg='dark slate gray')\n",
        "root.title('Video To Text Converter')\n",
        "\n",
        "def convert():\n",
        "    clip = mp.VideoFileClip(entry_vid.get()) \n",
        "    clip.audio.write_audiofile(entry_file.get()) \n",
        "        \n",
        "def text():\n",
        "    r = sr.Recognizer()\n",
        "    audio = sr.AudioFile(entry_file.get())\n",
        "    with audio as source:        \n",
        "        audtext = r.listen(source)\n",
        "        try:            \n",
        "            text1 = r.recognize_google(audtext)\n",
        "            st1.set(text1)\n",
        "        except:\n",
        "            st1.set('Try Again!')\n",
        "   \n",
        "def EXIT():\n",
        "    root.destroy()\n",
        "     \n",
        "    \n",
        "\n",
        "\n",
        "# Ltitle = Label(root,text='Video to Text Converter',font='Courier 16 underline bold',bg='dark slate gray',fg='mint cream').grid(row=0,column=2,ipadx=70)\n",
        "\n",
        "# Lvid = Label(root,text=\"Video Path :\",font='Constantia 14',bg='dark slate gray',fg='mint cream').grid(row=2,column=1,ipady=24,ipadx=18)\n",
        "# entry_vid = Entry(root,width=70)\n",
        "# entry_vid.insert(0,\"FILE PATH .mp4\")\n",
        "# entry_vid.place(x=150,y=60)\n",
        "# btn_con = Button(root,text='Convert to Text',font='Constantia 10',fg='maroon',command=convert).place(x=600,y=55)\n",
        "\n",
        "# Lfile = Label(root,text='File Name :',font='Constantia 14',bg='dark slate gray',fg='mint cream').grid(row=3,column=1,ipady=8,ipadx=18)\n",
        "# entry_file = Entry(root,width=70)\n",
        "# entry_file.insert(0,\"FILE NAME .wav\")\n",
        "# entry_file.place(x=150,y=120)\n",
        "\n",
        "# st1 =StringVar()\n",
        "# Ltext = Label(root,text=\"Text :\",font='Constantia 14',bg='dark slate gray',fg='mint cream').grid(row=4,column=1)\n",
        "# entry_text = Entry(root,width=70,textvariable=st1).grid(row=4,column=2,ipady=85)\n",
        "# btn_text = Button(root,text='Get Text',font='Constantia 10',command=text,fg='maroon').place(x=300,y=360)\n",
        "\n",
        "\n",
        "# butexit = Button(root,text= \"Exit\",command=EXIT,font='Constantia 10',fg='maroon').place(x=380,y=360)\n",
        "\n",
        "\n",
        "# root.mainloop()\n",
        "\n",
        "               \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Z0NqkD5LkJeK",
        "outputId": "2c9a4aa1-631f-41b3-d835-7a47c5ef2fef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2d7ac3656e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'750x420+480+0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBLOBp1HlupZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7QJmPtNlum7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qe2ciqgzlukW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BxJgQHsiluhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NblJA2cGlufR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Z8n7pnSnxnEj"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjxc7wpM3t2eCOK37U6Jzy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}