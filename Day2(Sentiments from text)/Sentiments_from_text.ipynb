{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ruY47ulAsnJy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ruY47ulAsnJy",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "731e9b4b-23b0-44ec-d00b-f6d7186c1a42",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\olia\\anaconda3\\envs\\final_project\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\olia\\anaconda3\\envs\\final_project\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.7/267.7 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     -------------------------------------- 298.0/298.0 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\olia\\anaconda3\\envs\\final_project\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1 regex-2022.10.31\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "So-R5NCSsznJ",
   "metadata": {
    "collapsed": true,
    "id": "So-R5NCSsznJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Olia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tSiq-3OOqTPG",
   "metadata": {
    "id": "tSiq-3OOqTPG",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Basiscs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581ea01-9b09-4bdf-b81a-19caaa511060",
   "metadata": {
    "id": "e581ea01-9b09-4bdf-b81a-19caaa511060"
   },
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()] #  build a list of individual words that are only made up of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973af14-acd6-4656-946e-1bc6381b53c8",
   "metadata": {
    "id": "f973af14-acd6-4656-946e-1bc6381b53c8"
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\") # creating a list of stopwords(words that don't have much meaning in themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de9dc9-4878-46bc-a31b-94737e5a3049",
   "metadata": {
    "id": "83de9dc9-4878-46bc-a31b-94737e5a3049"
   },
   "outputs": [],
   "source": [
    "words_filtered = [w for w in words if w.lower() not in stopwords] # remove stop words from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd67bd-70e7-45c2-bb0c-38467e678847",
   "metadata": {
    "id": "66cd67bd-70e7-45c2-bb0c-38467e678847"
   },
   "outputs": [],
   "source": [
    "words_filtered: list[str] = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62c562-f37f-451e-91e1-321df985847a",
   "metadata": {
    "id": "3e62c562-f37f-451e-91e1-321df985847a",
    "outputId": "1344dff5-0d21-4e9c-dce3-c771e92ff2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  the    of    to   and    in     a   our    we  that   for    is     I  will  have    be  this   are    We    on  with    it    by    as   all   not  must   The     s   can  more \n",
      "19191 12854 11868 11748  6936  5837  5141  4338  4309  4070  3621  3394  2959  2486  2481  2323  2273  2063  1857  1825  1767  1717  1663  1612  1591  1568  1520  1410  1396  1369 \n"
     ]
    }
   ],
   "source": [
    "fd.most_common(30)\n",
    "fd.tabulate(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11c411-408b-4bc7-b257-b534aa73339d",
   "metadata": {
    "id": "4a11c411-408b-4bc7-b257-b534aa73339d"
   },
   "outputs": [],
   "source": [
    "lower_fd = nltk.FreqDist([w.lower() for w in fd]) # bringing all the words to the lower case and find words friquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0092314-392a-4fd4-86d7-77bd1beb7bf6",
   "metadata": {
    "id": "e0092314-392a-4fd4-86d7-77bd1beb7bf6",
    "outputId": "516abe78-39b1-490c-f19d-802e9cb423c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       the         of         to        and         in        our         we        for         be       this         on       with        all      world       year       from        new   congress         at         an      peace    federal    program government        war   economic      great     united        tax   national \n",
      "         3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3          3 \n"
     ]
    }
   ],
   "source": [
    "lower_fd.most_common(30)\n",
    "lower_fd.tabulate(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B0f8wi4Wp-tV",
   "metadata": {
    "id": "B0f8wi4Wp-tV"
   },
   "source": [
    "### Sentiment Analysis with **nltk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "JzMlyG59vh_S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzMlyG59vh_S",
    "outputId": "2d5701fd-74b9-4b42-ef14-79fdfe7adb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neu\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"His mother had hid virus she died from AIDS related illness\"\"\"\n",
    "\n",
    "# Create a SentimentIntensityAnalyzer object\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Use the polarity_scores method to get the sentiment scores\n",
    "sentiment_scores = sia.polarity_scores(text)\n",
    "\n",
    "# Compare the sentiment scores and print the most probable\n",
    "keys_to_keep = ['neg', 'neu', 'pos']\n",
    "dict_to_compare = {k: sentiment_scores[k] for k in keys_to_keep}\n",
    "print(max(dict_to_compare, key=dict_to_compare.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01X_i02C9ZyP",
   "metadata": {
    "id": "01X_i02C9ZyP"
   },
   "source": [
    "### Sentiment Analysis with **sia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748Ig2bE0h1l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "748Ig2bE0h1l",
    "outputId": "a0f9f54b-921f-45fc-bde6-bfddc26626d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neu\n"
     ]
    }
   ],
   "source": [
    "sentiment = sia.polarity_scores(text)\n",
    "keys_to_keep1 = ['neg', 'neu', 'pos']\n",
    "dict_to_compare1 = {k: sentiment[k] for k in keys_to_keep1}\n",
    "print(max(dict_to_compare1, key=dict_to_compare.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zU_qkmEfvzbx",
   "metadata": {
    "id": "zU_qkmEfvzbx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
